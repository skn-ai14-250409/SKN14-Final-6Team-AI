"""
recipe_search.py â€” ë ˆì‹œí”¼ ê²€ìƒ‰ ë° ì¬ë£Œ ì¶”ì²œ ëª¨ë“ˆ 
ì±…ì„:
- ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ (Tavily API) í›„ ì‚¬ì´ë“œë°”ì— ê²°ê³¼ URL í‘œì‹œ
- ì‹œë‚˜ë¦¬ì˜¤ 2: íŠ¹ì • ë ˆì‹œí”¼ ì„ íƒ ì‹œ, URL í¬ë¡¤ë§ ë° LLMì„ í†µí•œ ì¬ë£Œ/ì¡°ë¦¬ë²• ì¶”ì¶œ
- ì¶”ì¶œëœ ì¬ë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‡¼í•‘ëª° ìƒí’ˆ(SKU)ì„ DBì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì‚¬ì´ë“œë°”ì— ì œì•ˆ
- ìµœì¢… ì‘ë‹µ ë©”ì‹œì§€(AIMessage)ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ ê·œê²©ì— ë§ëŠ” 'response' í‚¤ë¡œ í¬ë§·íŒ…
"""
import random
import logging
import os
import requests
import re
import json
from typing import Dict, Any, List, Optional
import mysql.connector
from mysql.connector import Error
from bs4 import BeautifulSoup

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (í™˜ê²½ì— ë§ê²Œ ì¡°ì •)
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from graph_interfaces import ChatState

# ê°œì¸ë§ì¶¤í™” ì •ì±… ì„í¬íŠ¸
from policy import (
    get_user_preferences, 
    create_personalized_search_keywords, 
    filter_recipe_ingredients,
    should_exclude_recipe_content
)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger("RECIPE_SEARCH")

# --- í™˜ê²½ ë³€ìˆ˜ ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

try:
    import openai
    openai_api_key = os.getenv("OPENAI_API_KEY")
    openai_client = openai.OpenAI(api_key=openai_api_key) if openai_api_key else None
    if not openai_client:
        logger.warning("OpenAI API key not found. LLM-based features will be disabled.")
except ImportError:
    openai_client = None
    logger.warning("OpenAI package not available. LLM-based features will be disabled.")

# --- DB ì„¤ì • ---
DB_CONFIG = {
    'host': os.getenv('DB_HOST', '127.0.0.1'),
    'user': os.getenv('DB_USER', 'qook_user'),
    'password': os.getenv('DB_PASS', 'qook_pass'),
    'database': os.getenv('DB_NAME', 'qook_chatbot'),
    'port': int(os.getenv('DB_PORT', 3306))
}

# --- ë©”ì¸ ë¼ìš°íŒ… í•¨ìˆ˜ ---
def recipe_search(state: ChatState) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ë‘ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ í•˜ë‚˜ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    1. ì¼ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰
    2. ì„ íƒëœ ë ˆì‹œí”¼ì˜ ì¬ë£Œ ì¶”ì²œ
    """
    logger.info("ë ˆì‹œí”¼ ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    query = state.query

    try:
        # ì‹œë‚˜ë¦¬ì˜¤ 2: ì‚¬ìš©ìê°€ ì‚¬ì´ë“œë°”ì—ì„œ íŠ¹ì • ë ˆì‹œí”¼ì˜ 'ì¬ë£Œ ì¶”ì²œë°›ê¸°'ë¥¼ í´ë¦­í•œ ê²½ìš°
        if "ì„ íƒëœ ë ˆì‹œí”¼:" in query and "URL:" in query:
            logger.info("ì‹œë‚˜ë¦¬ì˜¤ 2: ì„ íƒëœ ë ˆì‹œí”¼ ì¬ë£Œ ì¶”ì²œ ì‹œì‘")
            recipe = _handle_selected_recipe(query, state)
            return recipe
        
        # ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ì ì¸ ë ˆì‹œí”¼ ê´€ë ¨ ì§ˆë¬¸ì¸ ê²½ìš°
        else:
            logger.info("ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ ì‹œì‘")
            rewrite_query = state.rewrite.get("text", "")
            return _handle_general_recipe_search(query, rewrite_query, state)

    except Exception as e:
        logger.error(f"ë ˆì‹œí”¼ ê²€ìƒ‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return {
            "recipe": {"results": [], "ingredients": [], "error": str(e)},
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤, ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }

# --- ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ í•¸ë“¤ëŸ¬ ---
def _handle_general_recipe_search(original_query: str, rewrite_query: str, state: ChatState = None) -> Dict[str, Any]:
    """Tavily APIë¡œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ê³  ì‚¬ì´ë“œë°”ì— í‘œì‹œí•  URL ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # ê°œì¸ë§ì¶¤í™”: ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ
    user_preferences = {}
    if state and state.user_id:
        user_preferences = get_user_preferences(state.user_id)
        logger.info(f"ì‚¬ìš©ì {state.user_id} ê°œì¸ ì„ í˜¸ë„: {user_preferences}")
    
    # LLM ë˜ëŠ” ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ì— ìµœì í™”ëœ ì¿¼ë¦¬ ìƒì„±
    base_query = _extract_recipe_query(original_query, rewrite_query)
    
    # ê°œì¸ë§ì¶¤í™”: ê²€ìƒ‰ ì¿¼ë¦¬ì— ì„ í˜¸ë„ ë°˜ì˜
    if user_preferences:
        personalized_query, exclusion_keywords = create_personalized_search_keywords(base_query, user_preferences)
        logger.info(f"ê°œì¸ë§ì¶¤í™”ëœ ì¿¼ë¦¬: {personalized_query}")
        logger.info(f"ì œì™¸ í‚¤ì›Œë“œ: {exclusion_keywords}")
        recipe_query = personalized_query
    else:
        recipe_query = base_query
        exclusion_keywords = []
    
    # Tavilyë¡œ ì™¸ë¶€ ë ˆì‹œí”¼ ê²€ìƒ‰
    recipe_results = _search_with_tavily(recipe_query, user_preferences)
    
    # í”„ë¡ íŠ¸ì—”ë“œë¡œ ë³´ë‚¼ ìµœì¢… ë©”ì‹œì§€ ìƒì„±
    if recipe_results:
        personalized_msg = ""
        if user_preferences.get("vegan"):
            personalized_msg = " (ë¹„ê±´ ë ˆì‹œí”¼ ìœ„ì£¼ë¡œ ê²€ìƒ‰ë¨)"
        elif user_preferences.get("allergy") or user_preferences.get("unfavorite"):
            personalized_msg = " (ê°œì¸ ì„ í˜¸ë„ ë°˜ì˜ë¨)"
            
        message = (
            f"{len(recipe_results)}ê°œì˜ ë ˆì‹œí”¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤{personalized_msg}.\n\n"
            "ğŸ’¡ ì›í•˜ëŠ” ë ˆì‹œí”¼ë¥¼ í´ë¦­í•˜ì—¬ 'ì¬ë£Œ ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í•„ìš”í•œ ì¬ë£Œë“¤ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!"
        )
    else:
        message = "ê´€ë ¨ ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."

    return {
        "recipe": {
            "results": recipe_results,      # ì‚¬ì´ë“œë°”ì— í‘œì‹œë  ë ˆì‹œí”¼ URL ëª©ë¡
            "ingredients": [],              # ì´ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” ì¬ë£Œ ëª©ë¡ì´ ë¹„ì–´ìˆìŒ
            "search_query": recipe_query
        },
        "response": message  # chat.jsê°€ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ 'response' í‚¤ ì‚¬ìš©
    }

# --- ì‹œë‚˜ë¦¬ì˜¤ 2: ì„ íƒëœ ë ˆì‹œí”¼ ì¬ë£Œ ì¶”ì²œ í•¸ë“¤ëŸ¬ ---

def _handle_selected_recipe(query: str, state: ChatState = None) -> Dict[str, Any]:
    """ì„ íƒëœ ë ˆì‹œí”¼ URLì„ í¬ë¡¤ë§í•˜ê³ , ì¬ë£Œë¥¼ ì¶”ì¶œí•˜ì—¬ DB ìƒí’ˆê³¼ ë§¤í•‘í•©ë‹ˆë‹¤."""
    
    # ê°œì¸ë§ì¶¤í™”: ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ
    user_preferences = {}
    if state and state.user_id:
        user_preferences = get_user_preferences(state.user_id)
        logger.info(f"ì‚¬ìš©ì {state.user_id} ê°œì¸ ì„ í˜¸ë„: {user_preferences}")
    
    # ì¿¼ë¦¬ì—ì„œ URL ì¶”ì¶œ
    recipe_url = _extract_recipe_url(query)
    if not recipe_url:
        logger.info("ë ˆì‹œí”¼ URLì„ ì°¾ì§€ ëª»í•¨")
        return {
            "recipe": {"results": [], "ingredients": []},
            "response": "ë ˆì‹œí”¼ URLì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¬ë£Œë¥¼ ì¶”ì²œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    
    # URL í¬ë¡¤ë§ ë° LLMì„ í†µí•œ ë‚´ìš© êµ¬ì¡°í™”
    structured_content = _scrape_and_structure_recipe(recipe_url)
    if not structured_content or not structured_content.get("ingredients"):
        logger.info("ë ˆì‹œí”¼ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŒ")
        return {
            "recipe": {"results": [], "ingredients": []},
            "response": "ë ˆì‹œí”¼ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ì–´ ì¬ë£Œ ì¶”ì²œì´ ì–´ë µìŠµë‹ˆë‹¤."
        }
    
    logger.info(f"ë ˆì‹œí”¼ êµ¬ì¡°í™” ì™„ë£Œ: {structured_content.get('title', 'ì œëª© ì—†ìŒ')}")
    
    # ì¶”ì¶œëœ ì¬ë£Œ ëª©ë¡ (ì˜ˆ: ["ì‚¬ê³¼", "ë¼ì§€ê³ ê¸°", "ì–‘íŒŒ"])
    extracted_ingredients = structured_content.get("ingredients", [])
    
    # ê°œì¸ë§ì¶¤í™”: ì‚¬ìš©ì ì„ í˜¸ë„ì— ë§ì§€ ì•ŠëŠ” ì¬ë£Œ í•„í„°ë§
    if user_preferences:
        filtered_ingredients = filter_recipe_ingredients(extracted_ingredients, user_preferences)
        logger.info(f"ê°œì¸ë§ì¶¤í™” í•„í„°ë§: {len(extracted_ingredients)} -> {len(filtered_ingredients)}")
        extracted_ingredients = filtered_ingredients
        
        # í•„í„°ë§ëœ ì¬ë£Œë¡œ êµ¬ì¡°í™”ëœ ì»¨í…ì¸  ì—…ë°ì´íŠ¸
        structured_content["ingredients"] = extracted_ingredients
    
    # âœ… ì¶”ê°€: stateì—ì„œ rewrite.keywordsë„ í™œìš©
    additional_keywords = []
    if state and state.rewrite.get("keywords"):
        # ì¬ë£Œ ê´€ë ¨ í‚¤ì›Œë“œë§Œ í•„í„°ë§ (êµ¬ë§¤, ì¬ë£Œ ë“±ì€ ì œì™¸)
        filtered_keywords = [
            k for k in state.rewrite["keywords"] 
            if k not in ['ì¬ë£Œ', 'êµ¬ë§¤', 'ìƒí’ˆ', 'ì¶”ì²œ', 'ì‡¼í•‘ëª°']
        ]
        additional_keywords.extend(filtered_keywords)
    
    # ì¬ë£Œëª…ê³¼ í‚¤ì›Œë“œ í•©ì¹˜ê¸° (ì¤‘ë³µ ì œê±°)
    all_search_terms = list(set(extracted_ingredients + additional_keywords))
    logger.info(f"DB ê²€ìƒ‰ í‚¤ì›Œë“œ: {all_search_terms}")
    
    # ì¬ë£Œëª…ìœ¼ë¡œ DBì˜ ìƒí’ˆ ëª©ë¡ ê²€ìƒ‰ (LIKE ê²€ìƒ‰)
    matched_products = _get_product_details_from_db(all_search_terms, user_preferences)
    
    # AIMessageë¡œ ë³´ì—¬ì¤„ ë ˆì‹œí”¼ ë‚´ìš© í¬ë§·íŒ…
    formatted_recipe_message = _format_recipe_content(structured_content, user_preferences)
    
    logger.info(f"ë ˆì‹œí”¼ ì²˜ë¦¬ ì™„ë£Œ: ì¬ë£Œ {len(all_search_terms)}ê°œ, ì¶”ì²œ ìƒí’ˆ {len(matched_products)}ê°œ")
    print("recipe_search.py matched_products:",matched_products)
    print("recipe_search.py formatted_recipe_message:",formatted_recipe_message)
    print("recipe_search.py structured_content:",structured_content)
    return {
        "recipe": {
            "results": [],
            "ingredients": matched_products,
            "selected_recipe": structured_content
        },
        "meta": {
            "final_message": formatted_recipe_message 
        }
    }

def get_db_connection():
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except Error as e:
        logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def _get_product_details_from_db(ingredient_names: List[str], user_preferences: Dict[str, Any] = None) -> List[Dict[str, Any]]:
    """DBì—ì„œ ì¬ë£Œëª…ì„ í¬í•¨(LIKE)í•˜ëŠ” ìƒí’ˆ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    if not ingredient_names:
        return []

    conn = get_db_connection()
    if not conn:
        return []

    try:
        with conn.cursor(dictionary=True) as cursor:
            # ê°œì¸ë§ì¶¤í™”: ì‚¬ìš©ì ì„ í˜¸ë„ì— ë”°ë¥¸ ì œì™¸ ì¡°ê±´ ìƒì„±
            exclusion_conditions = []
            
            if user_preferences:
                # ë¹„ê±´ ì‚¬ìš©ìì˜ ê²½ìš° ë™ë¬¼ì„± ì œí’ˆ ì œì™¸
                if user_preferences.get("vegan", False):
                    vegan_exclusions = [
                        "ê³ ê¸°", "ë¼ì§€", "ì†Œê³ ê¸°", "ë‹­", "ìƒì„ ", "ìƒˆìš°", "ì˜¤ì§•ì–´", 
                        "ê³„ë€", "ë‹¬ê±€", "ìš°ìœ ", "ì¹˜ì¦ˆ", "ë²„í„°", "ìš”êµ¬ë¥´íŠ¸", "ë² ì´ì»¨", 
                        "í–„", "ì†Œì‹œì§€", "ì°¸ì¹˜", "ì—°ì–´", "ë©¸ì¹˜", "ì “ê°ˆ"
                    ]
                    for exclusion in vegan_exclusions:
                        exclusion_conditions.append(f"p.product NOT LIKE '%{exclusion}%'")
                    logger.info("ë¹„ê±´ ì‚¬ìš©ì - ë™ë¬¼ì„± ì œí’ˆ ì œì™¸ ì¡°ê±´ ì¶”ê°€")
                
                # ì•ŒëŸ¬ì§€ ì œì™¸
                if user_preferences.get("allergy"):
                    allergy_items = [item.strip() for item in user_preferences["allergy"].split(",")]
                    for allergy in allergy_items:
                        exclusion_conditions.append(f"p.product NOT LIKE '%{allergy}%'")
                    logger.info(f"ì•ŒëŸ¬ì§€ ì œì™¸ ì¡°ê±´ ì¶”ê°€: {allergy_items}")
                
                # ì‹«ì–´í•˜ëŠ” ìŒì‹ ì œì™¸
                if user_preferences.get("unfavorite"):
                    unfavorite_items = [item.strip() for item in user_preferences["unfavorite"].split(",")]
                    for unfavorite in unfavorite_items:
                        exclusion_conditions.append(f"p.product NOT LIKE '%{unfavorite}%'")
                    logger.info(f"ì„ í˜¸ë„ ì œì™¸ ì¡°ê±´ ì¶”ê°€: {unfavorite_items}")
            
            # ì—¬ëŸ¬ LIKE ì¡°ê±´ì„ ORë¡œ ì—°ê²°í•˜ëŠ” ì¿¼ë¦¬ ìƒì„±
            where_clauses = ' OR '.join(['p.product LIKE %s'] * len(ingredient_names))
            
            # ì œì™¸ ì¡°ê±´ì´ ìˆë‹¤ë©´ ANDë¡œ ì¶”ê°€
            exclusion_clause = ""
            if exclusion_conditions:
                exclusion_clause = " AND " + " AND ".join(exclusion_conditions)
            
            sql = f"""
                SELECT p.product as name, p.unit_price as price, p.origin, p.organic
                FROM product_tbl p
                WHERE ({where_clauses}){exclusion_clause}
                LIMIT 15
            """
            
            # LIKE ê²€ìƒ‰ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ìƒì„± (ì˜ˆ: 'ì‚¬ê³¼' -> '%ì‚¬ê³¼%')
            params = [f"%{name}%" for name in ingredient_names]
            
            cursor.execute(sql, params)
            products = cursor.fetchall()

            # í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë°ì´í„° í¬ë§·íŒ…
            formatted_products = []
            for p in products:
                formatted_products.append({
                    'name': p.get('name', ''),
                    'price': float(p.get('price', 0.0)),
                    'origin': p.get('origin', 'ì •ë³´ ì—†ìŒ'),
                    'organic': True if p.get('organic') == 'Y' else False
                })
            
            logger.info(f"ê°œì¸ë§ì¶¤í™” ìƒí’ˆ í•„í„°ë§ ì™„ë£Œ: {len(formatted_products)}ê°œ ìƒí’ˆ")
            return formatted_products
            
    except Error as e:
        logger.error(f"ìƒí’ˆ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    finally:
        if conn and conn.is_connected():
            conn.close()

# --- Helper Functions: ì™¸ë¶€ API ë° í¬ë¡¤ë§ ---
def _is_crawlable_url(url: str) -> bool:
    """URLì´ í¬ë¡¤ë§ ê°€ëŠ¥í•œì§€ ê°„ë‹¨íˆ íŒë‹¨í•©ë‹ˆë‹¤."""
    from urllib.parse import urlparse
    
    try:
        parsed = urlparse(url.lower())
        domain = parsed.netloc.replace('www.', '')
        
        # í™•ì‹¤íˆ ì œì™¸í•  ì‚¬ì´íŠ¸ë“¤ (ë™ì˜ìƒ/SNS)
        excluded_patterns = ['youtube.', 'youtu.be', 'instagram.', 'facebook.', 'tiktok.', 'pinterest.']
        if any(pattern in domain for pattern in excluded_patterns):
            return False
        
        # HTML í˜ì´ì§€ì¸ì§€ ê°„ë‹¨ í™•ì¸ (í™•ì¥ì ì²´í¬)
        path = parsed.path.lower()
        if path.endswith(('.mp4', '.avi', '.mov', '.pdf', '.jpg', '.png', '.gif')):
            return False
            
        return True
        
    except Exception:
        return False

def _quick_validate_url(url: str) -> bool:
    """URLì´ ì‹¤ì œë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.head(url, headers=headers, timeout=3)
        
        # 200ëŒ€ ì‘ë‹µì´ê³  HTML ì½˜í…ì¸ ì¸ì§€ í™•ì¸
        if 200 <= response.status_code < 300:
            content_type = response.headers.get('content-type', '').lower()
            return 'text/html' in content_type
            
        return False
    except Exception:
        return False

def _search_with_tavily(query: str, user_preferences: Dict[str, Any] = None) -> List[Dict[str, Any]]:
    """Tavily APIë¡œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ê³ , ê²°ê³¼ë¥¼ ì„ì€ í›„ ê²€ì¦í•©ë‹ˆë‹¤."""
    try:
        from tavily import TavilyClient
        client = TavilyClient(api_key=TAVILY_API_KEY)
        
        logger.info(f"Tavily ê²€ìƒ‰ ì‹¤í–‰: '{query}'")
        
        # ê°œì¸ë§ì¶¤í™”: ê²€ìƒ‰ ì¿¼ë¦¬ì— ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€
        exclusion_terms = ["-youtube", "-instagram", "-facebook", "-tiktok", "-blog.naver.com", "-m.blog.naver.com"]
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€
        if user_preferences:
            # ë¹„ê±´ ì‚¬ìš©ìì˜ ê²½ìš° ìœ¡ë¥˜ ê´€ë ¨ ì œì™¸
            if user_preferences.get("vegan", False):
                meat_exclusions = ["-ê³ ê¸°", "-ë¼ì§€ê³ ê¸°", "-ì†Œê³ ê¸°", "-ë‹­ê³ ê¸°", "-ìƒì„ ", "-ìœ¡ë¥˜"]
                exclusion_terms.extend(meat_exclusions)
                logger.info("ë¹„ê±´ ì‚¬ìš©ì - ìœ¡ë¥˜ ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ ì œì™¸")
            
            # ì•ŒëŸ¬ì§€ ê´€ë ¨ ì œì™¸
            if user_preferences.get("allergy"):
                allergy_items = user_preferences["allergy"].split(",")
                for item in allergy_items:
                    exclusion_terms.append(f"-{item.strip()}")
                logger.info(f"ì•ŒëŸ¬ì§€ ê¸°ë°˜ ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€: {allergy_items}")
            
            # ì‹«ì–´í•˜ëŠ” ìŒì‹ ì œì™¸
            if user_preferences.get("unfavorite"):
                unfavorite_items = user_preferences["unfavorite"].split(",")
                for item in unfavorite_items:
                    exclusion_terms.append(f"-{item.strip()}")
                logger.info(f"ì„ í˜¸ë„ ê¸°ë°˜ ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€: {unfavorite_items}")
        
        enhanced_query = f"{query} ë ˆì‹œí”¼ {' '.join(exclusion_terms)}"
        
        search_result = client.search(
            query=enhanced_query,
            search_depth="basic",
            max_results=20  # ## ë³€ê²½ì  2: ê²€ìƒ‰ ê²°ê³¼ ìš”ì²­ ê°œìˆ˜ë¥¼ 20ê°œë¡œ ëŠ˜ë¦¼
        )
        
        # ## ë³€ê²½ì  3: ë°›ì•„ì˜¨ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê³  ìˆœì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ìŒ
        search_results_list = search_result.get("results", [])
        random.shuffle(search_results_list)

        validated_results = []
        
        # ë¬´ì‘ìœ„ë¡œ ì„ì¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ê²€ì¦ ì‹œì‘
        for res in search_results_list:
            url = res.get("url", "")
            
            # 1ë‹¨ê³„: ê¸°ë³¸ URL íŒ¨í„´ ê²€ì¦
            if not url or not _is_crawlable_url(url):
                continue
            
            # 2ë‹¨ê³„: ì‹¤ì œ ì ‘ê·¼ ê°€ëŠ¥ì„± ê²€ì¦ (ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ìµœì†Œí™”ë¥¼ ìœ„í•´ í•„ìš”í•œ ë§Œí¼ë§Œ)
            if not _quick_validate_url(url):
                logger.info(f"ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ URL ì œì™¸: {url}")
                continue
            
            # 3ë‹¨ê³„: ê°œì¸ë§ì¶¤í™” í•„í„°ë§ - ì œëª©ê³¼ ë‚´ìš© ê¸°ë°˜
            if user_preferences and should_exclude_recipe_content(
                res.get("title", ""), res.get("content", ""), user_preferences
            ):
                logger.info(f"ê°œì¸ ì„ í˜¸ë„ì— ì˜í•´ ì œì™¸ëœ ë ˆì‹œí”¼: {res.get('title', 'Unknown')}")
                continue
            
            # LLMìœ¼ë¡œ titleê³¼ contentë¥¼ 20~30ê¸€ìë¡œ ìš”ì•½
            original_title = res.get("title", "ì œëª© ì—†ìŒ")
            content = res.get("content", "")
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            title = original_title[:30] + ("..." if len(original_title) > 30 else "")
            description = content[:150]
            
            if openai_client and (original_title or content):
                try:
                    # ì œëª© ìš”ì•½
                    if original_title:
                        title_response = openai_client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "ë‹¤ìŒ ë ˆì‹œí”¼ ì œëª©ì„ 30ê¸€ì ë‚´ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì¤˜. ì˜ˆì‹œ: 'ìì·¨ìƒë„ ì‰½ê²Œ ë§Œë“œëŠ” ì´ˆê°„ë‹¨ ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼' / 'ìê¾¸ ë•¡ê¸°ëŠ” ë§ˆì•½ì–‘ë…ì˜ ë§¤ì½¤í•œ ë‹­ë³¶ìŒíƒ• ì¡°ë¦¬ë²•"},
                                {"role": "user", "content": f"ì œëª© ìš”ì•½: {original_title}"}
                            ],
                            temperature=0.1, max_tokens=20
                        )
                        title_summary = title_response.choices[0].message.content.strip()
                        # ë”°ì˜´í‘œ ì œê±°
                        title_summary = title_summary.strip('"').strip("'")
                        title = title_summary[:30] + ("..." if len(title_summary) > 30 else "")
                    
                    # ë‚´ìš© ìš”ì•½
                    if content:
                        desc_response = openai_client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "ë‹¤ìŒ ë ˆì‹œí”¼ ë‚´ìš©ì„ 20~30ê¸€ìë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì¤˜. ë‹µë³€ ì˜ˆì‹œ 1: ê¹€ì¹˜Â·ì°¸ì¹˜ ë³¶ì•„ ë‘ë¶€ ì˜¬ë¦° ë§¤ì½¤ì°Œê°œ ì™„ì„±. ë‹µë³€ ì˜ˆì‹œ 2: ë‹­ê³ ê¸° ë°ì³ ì±„ì†Œ ë„£ê³  ë§¤ì½¤í•˜ê²Œ ë“ì¸ ë‹­ë³¶ìŒíƒ•"},
                                {"role": "user", "content": f"ìš”ì•½: {content[:300]}"}
                            ],
                            temperature=0.1, max_tokens=30
                        )
                        desc_summary = desc_response.choices[0].message.content.strip()
                        description = desc_summary[:30] + ("..." if len(desc_summary) > 30 else "")
                except Exception:
                    pass  # ì˜¤ë¥˜ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©

            validated_results.append({
                "title": title,
                "url": url,
                "description": description            
            })
            
            # ì›í•˜ëŠ” ê°œìˆ˜(3ê°œ)ë§Œí¼ ì°¾ìœ¼ë©´ ì¤‘ë‹¨
            if len(validated_results) >= 3:
                break
        
        logger.info(f"ê²€ì¦ëœ ë ˆì‹œí”¼ URL: {len(validated_results)}ê°œ")
        return validated_results
        
    except Exception as e:
        logger.error(f"Tavily ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def _scrape_and_structure_recipe(url: str) -> Optional[Dict[str, Any]]:
    """URLì„ í¬ë¡¤ë§í•˜ê³  LLMì„ ì‚¬ìš©í•´ ë‚´ìš©ì„ êµ¬ì¡°í™”í•©ë‹ˆë‹¤."""
    logger.info(f"URL í¬ë¡¤ë§ ë° ë¶„ì„ ì‹œì‘: {url}")
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        page_text = soup.get_text(separator='\n', strip=True)
        
        if not openai_client:
            logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ ë ˆì‹œí”¼ êµ¬ì¡°í™” ë¶ˆê°€.")
            return None
            
        return _llm_extract_recipe_content(page_text[:4000])

    except Exception as e:
        logger.error(f"URL í¬ë¡¤ë§ ë° êµ¬ì¡°í™” ì‹¤íŒ¨ {url}: {e}")
        return None

# --- Helper Functions: LLM ì²˜ë¦¬ ---
def _extract_recipe_query(original_query: str, rewrite_query: str = "") -> str:
    """ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ ë ˆì‹œí”¼ëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not openai_client:
        return f"{original_query} ë ˆì‹œí”¼"

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ìš”ë¦¬ ì´ë¦„ë§Œ ì¶”ì¶œí•´ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ 'ê¹€ì¹˜ì°Œê°œ ë§›ìˆê²Œ ë“ì´ëŠ” ë²• ì•Œë ¤ì¤˜' -> 'ê¹€ì¹˜ì°Œê°œ'"},
                {"role": "user", "content": f"ì›ë³¸: '{original_query}', ì¬ì‘ì„±: '{rewrite_query}'"}
            ],
            temperature=0.1, max_tokens=50
        )
        return response.choices[0].message.content.strip().strip('"')
    except Exception as e:
        logger.error(f"LLM ì¿¼ë¦¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return f"{original_query} ë ˆì‹œí”¼"

def _llm_extract_recipe_content(page_text: str) -> Dict[str, Any]:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤."""
    system_prompt = """ë‹¹ì‹ ì€ ì‹ ì„ ì‹í’ˆ ì‡¼í•‘ëª°ì„ ìœ„í•œ ë ˆì‹œí”¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ê³ ê°ì—ê²Œ í•„ìš”í•œ ì¬ë£Œë¥¼ ì¶”ì²œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

**ì¶”ì¶œ ê·œì¹™:**
1. **title**: ìš”ë¦¬ì˜ ì •í™•í•œ ì´ë¦„ (ì˜ˆ: "ê¹€ì¹˜ì°Œê°œ", "ìˆ˜ë°•í™”ì±„")
2. **ingredients**: ì‡¼í•‘ëª°ì—ì„œ êµ¬ë§¤ ê°€ëŠ¥í•œ ì‹ ì„ ì‹í’ˆ ì¬ë£Œë§Œ ì¶”ì¶œ
    - name: ì¬ë£Œì˜ í•µì‹¬ ëª…ì‚¬ í˜•íƒœë¡œ í‘œì¤€í™”í•©ë‹ˆë‹¤. (ì˜ˆ: 'ëŒ€íŒŒ', 'ì–‘íŒŒ', 'ë¼ì§€ê³ ê¸°')
    - quantity: ìˆ˜ëŸ‰ì„ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤. ë¶„ìˆ˜('1/2')ëŠ” ì†Œìˆ˜ì (0.5)ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ìˆ˜ëŸ‰ì´ ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ 1ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
    - unit: ë‹¨ìœ„ë¥¼ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤. (ì˜ˆ: 'g', 'ê°œ', 'ì»µ', 'T', 't')
    - í¬í•¨í•  ê²ƒ: ì‹ ì„ ì‹í’ˆ(ìœ¡ë¥˜, ì±„ì†Œ, ê³¼ì¼), êµ¬ë§¤ ê°€ëŠ¥í•œ ê°€ê³µì‹í’ˆ(ë‘ë¶€, ë©´, í†µì¡°ë¦¼), ì–‘ë…/ì¡°ë¯¸ë£Œ(ê°„ì¥, ëœì¥, ì°¸ê¸°ë¦„, ë‹¤ì§„ ë§ˆëŠ˜)
    - ì œì™¸í•  ê²ƒ: ë¬¼, ì†Œê¸ˆ, í›„ì¶”, ì„¤íƒ•, ì‹ìš©ìœ  ë“± ì‚¬ìš©ìê°€ ê¸°ë³¸ì ìœ¼ë¡œ ë³´ìœ í•˜ê³  ìˆì„ ë²•í•œ í’ˆëª©
3. **instructions**: ê³ ê°ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¡°ë¦¬ë²• ìš”ì•½
    - ì´ˆë³´ìë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê° ë‹¨ê³„ë¥¼ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
    - ê° ë‹¨ê³„ëŠ” '\n'ìœ¼ë¡œ êµ¬ë¶„(ì¤‘ìš”)
    - ì „ë¬¸ ìš©ì–´ë³´ë‹¤ëŠ” ì¼ë°˜ì ì¸ í‘œí˜„ ì‚¬ìš©
    - ê°€ì—´ ì˜¨ë„(ì˜ˆ: ì¤‘ë¶ˆ), ì¡°ë¦¬ ì‹œê°„(ì˜ˆ: 5ë¶„ê°„) ë“± êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

**ì¶œë ¥ í˜•ì‹:**
ë°˜ë“œì‹œ ë‹¤ìŒ JSON êµ¬ì¡°ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
```json
{
    "title": "ìš”ë¦¬ëª…",
    "ingredients": ["ì¬ë£Œ1", "ì¬ë£Œ2", "ì¬ë£Œ3"],
    "instructions": "1ë‹¨ê³„ ì„¤ëª…\n2ë‹¨ê³„ ì„¤ëª…\n3ë‹¨ê³„ ì„¤ëª…"
}
```

**ì˜ˆì‹œ:**
ì…ë ¥: "ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼... ë¼ì§€ê³ ê¸° 200g, ê¹€ì¹˜ 300g, ì–‘íŒŒ 1ê°œ, ëŒ€íŒŒ 2ëŒ€, ë‘ë¶€ 1ëª¨..."
ì¶œë ¥:
```json
{
  "title": "ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ",
  "ingredients": ["ë¼ì§€ê³ ê¸°", "ê¹€ì¹˜", "ë‘ë¶€", "ì–‘íŒŒ", "ëŒ€íŒŒ", "êµ­ê°„ì¥", "ê³ ì¶§ê°€ë£¨"],
  "instructions": "1. ë‹¬êµ° ëƒ„ë¹„ì— ë¼ì§€ê³ ê¸°ë¥¼ ë„£ê³  ì¤‘ë¶ˆì—ì„œ ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ì•½ 3ë¶„ê°„ ë³¶ì•„ì¤ë‹ˆë‹¤.\n2. ë¼ì§€ê³ ê¸°ê°€ ìµìœ¼ë©´ ê¹€ì¹˜ë¥¼ ë„£ê³  5ë¶„ê°„ í•¨ê»˜ ì¶©ë¶„íˆ ë³¶ì•„ ê¹Šì€ ë§›ì„ ë”í•´ì¤ë‹ˆë‹¤.\n3. ë¬¼ì„ ìì‘í•˜ê²Œ ë¶“ê³  ë“ì–´ì˜¤ë¥´ë©´, êµ­ê°„ì¥ê³¼ ê³ ì¶§ê°€ë£¨ë¥¼ ë„£ê³  ì¤‘ë¶ˆì—ì„œ 10ë¶„ê°„ ë” ë“ì—¬ì¤ë‹ˆë‹¤.\n4. ë§ˆì§€ë§‰ìœ¼ë¡œ ë‘ë¶€, ì–‘íŒŒ, ëŒ€íŒŒë¥¼ ë„£ê³  5ë¶„ê°„ í•œì†Œë” ë” ë“ì—¬ ì™„ì„±í•©ë‹ˆë‹¤."
}
```

ì¤‘ìš”: JSON í˜•ì‹ ì™¸ì— ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."""
    user_prompt = f"ë‹¤ìŒ ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì¤˜:\n\n---\n{page_text}\n---"

    response = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.2, max_tokens=1024
    )
    
    try:
        content = json.loads(response.choices[0].message.content)
        if isinstance(content.get("ingredients"), str):
            content["ingredients"] = [item.strip() for item in content["ingredients"].split(',')]
        return content
    except (json.JSONDecodeError, AttributeError) as e:
        logger.error(f"LLM JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return {}

def _extract_recipe_url(query: str) -> Optional[str]:
    """ì¿¼ë¦¬ ë¬¸ìì—´ì—ì„œ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    match = re.search(r'URL:\s*(https?://[^\s]+)', query)
    if match:
        return match.group(1)
    logger.warning(f"ì¿¼ë¦¬ì—ì„œ URLì„ ì°¾ì§€ ëª»í•¨: {query}")
    return None

def _format_recipe_content(structured_content: Dict[str, Any], user_preferences: Dict[str, Any] = None) -> str:
    """êµ¬ì¡°í™”ëœ ë ˆì‹œí”¼ ë°ì´í„°ë¥¼ AIMessageì— í‘œì‹œí•  ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    title = structured_content.get("title", "ë ˆì‹œí”¼ ì •ë³´")
    ingredients = structured_content.get("ingredients", [])
    instructions = structured_content.get("instructions", "ì¡°ë¦¬ë²• ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    ingredients_text = "\n".join(f"- {ing}" for ing in ingredients[:10])
    if len(ingredients) > 10:
        ingredients_text += "\n- ë“±..."

    # ê°œì¸ë§ì¶¤í™” ë©”ì‹œì§€ ì¶”ê°€
    personalized_note = ""
    if user_preferences:
        if user_preferences.get("vegan"):
            personalized_note += "**ğŸŒ± ë¹„ê±´ ë ˆì‹œí”¼ë¡œ ê°œì¸ë§ì¶¤í™”ë˜ì—ˆìŠµë‹ˆë‹¤.**\n"
        if user_preferences.get("allergy"):
            personalized_note += f"**âš ï¸ ì•ŒëŸ¬ì§€({user_preferences['allergy']}) ì •ë³´ê°€ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.**\n"
        if user_preferences.get("unfavorite"):
            personalized_note += f"**âŒ ì„ í˜¸í•˜ì§€ ì•ŠëŠ” ìŒì‹({user_preferences['unfavorite']})ì´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.**\n"
        if personalized_note:
            personalized_note += "\n"

    formatted_message = (
        f"**{title}**\n\n"
        f"{personalized_note}"
        f"**í•„ìš”í•œ ì¬ë£Œ:**\n{ingredients_text}\n\n"
        f"**ì¡°ë¦¬ë²• ìš”ì•½:**\n{instructions}\n\n"
        "---\n"
        "**ìš°ì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì¶”ì²œ ì¬ë£Œë“¤ì„ ë°”ë¡œ ì¥ë°”êµ¬ë‹ˆì— ë‹´ì•„ë³´ì„¸ìš”!**\n"
        "**í•„ìš”í•œ ì¬ë£Œê°€ ìƒí’ˆì— ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ìƒí’ˆì´ ì¶”ì²œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**"
    )
    
    return formatted_message