"""
recipe_search.py â€” ë ˆì‹œí”¼ ê²€ìƒ‰ ë° ì¬ë£Œ ì¶”ì²œ ëª¨ë“ˆ 
ì±…ì„:
- ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ (Tavily API) í›„ ì‚¬ì´ë“œë°”ì— ê²°ê³¼ URL í‘œì‹œ
- ì‹œë‚˜ë¦¬ì˜¤ 2: íŠ¹ì • ë ˆì‹œí”¼ ì„ íƒ ì‹œ, URL í¬ë¡¤ë§ ë° LLMì„ í†µí•œ ì¬ë£Œ/ì¡°ë¦¬ë²• ì¶”ì¶œ
- ì¶”ì¶œëœ ì¬ë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‡¼í•‘ëª° ìƒí’ˆ(SKU)ì„ DBì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì‚¬ì´ë“œë°”ì— ì œì•ˆ
- ìµœì¢… ì‘ë‹µ ë©”ì‹œì§€(AIMessage)ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ ê·œê²©ì— ë§ëŠ” 'response' í‚¤ë¡œ í¬ë§·íŒ…
"""
import random
import logging
import os
import requests
import re
import json
from typing import Dict, Any, List, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from mysql.connector import Error
from bs4 import BeautifulSoup

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (í™˜ê²½ì— ë§ê²Œ ì¡°ì •)
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from graph_interfaces import ChatState

# ê°œì¸ë§ì¶¤í™” ì •ì±… ì„í¬íŠ¸
from policy import (
    get_user_preferences, 
    create_personalized_search_keywords, 
    filter_recipe_ingredients,
    should_exclude_recipe_content,
    EXCLUDED_DOMAINS
)

from utils.chat_history import save_recipe_search_result, generate_alternative_search_strategy
from nodes.product_search import get_search_engine  # hjs ìˆ˜ì • # ë©€í‹°í„´ ê¸°ëŠ¥
from utils.db import get_db_connection  # hjs ìˆ˜ì •

logger = logging.getLogger("RECIPE_SEARCH")

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

try:
    import openai
    openai_api_key = os.getenv("OPENAI_API_KEY")
    openai_client = openai.OpenAI(api_key=openai_api_key) if openai_api_key else None
    if not openai_client:
        logger.warning("OpenAI API key not found. LLM-based features will be disabled.")
except ImportError:
    openai_client = None
    logger.warning("OpenAI package not available. LLM-based features will be disabled.")

def recipe_search(state: ChatState) -> Dict[str, Any]:
    """
    íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ (ì¬ê²€ìƒ‰ ê°œì„  ë²„ì „)
    - ê¸°ì¡´ ì‹œë‚˜ë¦¬ì˜¤ 1, 2 ì™„ì „ ìœ ì§€
    - ê²€ìƒ‰ ì™„ë£Œ í›„ íˆìŠ¤í† ë¦¬ ì €ì¥ ì¶”ê°€
    - ì¬ê²€ìƒ‰ì¼ ê²½ìš° ì´ì „ ê²°ê³¼ í•„í„°ë§ ì ìš©
    - ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì™„ë²½ í´ë°±
    """
    logger.info("íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    query = state.query

    try:
        # ì¬ê²€ìƒ‰ ì—¬ë¶€ í™•ì¸ (ì•ˆì „í•œ ë°©ì‹)
        is_alternative_search = False
        search_strategy = None
        previous_urls = []

        try:
            search_context = state.slots.get('search_context')
            if search_context and search_context.get('type') == 'alternative':
                is_alternative_search = True
                logger.info(f"ì¬ê²€ìƒ‰ ê°ì§€: {search_context.get('intent_scope', 'unknown')}")

                # ëŒ€ì•ˆ ê²€ìƒ‰ ì „ëµ ìƒì„±
                if search_context.get('previous_dish'):
                    # ì‹¤ì œ íˆìŠ¤í† ë¦¬ì—ì„œ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                    from utils.chat_history import get_recent_recipe_search_context
                    recent_context = get_recent_recipe_search_context(state, query)

                    previous_results = []
                    if recent_context["has_previous_search"] and recent_context["most_recent_search"]:
                        previous_results = recent_context["most_recent_search"].get("results", [])
                        logger.info(f"íˆìŠ¤í† ë¦¬ì—ì„œ ê°€ì ¸ì˜¨ ì´ì „ ê²€ìƒ‰ ê²°ê³¼: {len(previous_results)}ê°œ")

                    previous_search = {
                        "search_query": search_context.get('previous_dish'),
                        "query_type": "specific_dish",
                        "results": previous_results  # ì‹¤ì œ íˆìŠ¤í† ë¦¬ ê²°ê³¼ ì‚¬ìš©
                    }
                    search_strategy = generate_alternative_search_strategy(previous_search, query)
                    previous_urls = search_strategy.get('exclude_urls', [])
                    logger.info(f"ëŒ€ì•ˆ ê²€ìƒ‰ ì „ëµ: {search_strategy.get('strategy_type', 'unknown')}")
                    logger.info(f"ì œì™¸í•  URL: {len(previous_urls)}ê°œ")

        except Exception as e:
            logger.warning(f"ì¬ê²€ìƒ‰ ë¶„ì„ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}")
            is_alternative_search = False

        # ê¸°ì¡´ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸° (ì™„ì „ ë™ì¼)
        if "ì„ íƒëœ ë ˆì‹œí”¼:" in query and "URL:" in query:
            logger.info("ì‹œë‚˜ë¦¬ì˜¤ 2: ì„ íƒëœ ë ˆì‹œí”¼ ì¬ë£Œ ì¶”ì²œ ì‹œì‘")
            result = _handle_selected_recipe(query, state)
        else:
            logger.info("ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ ì‹œì‘")
            rewrite_query = state.rewrite.get("text", "")

            # ì¬ê²€ìƒ‰ì¸ ê²½ìš° ê²€ìƒ‰ ì „ëµ ì ìš©
            if is_alternative_search and search_strategy:
                result = _handle_general_recipe_search_with_history(
                    query, rewrite_query, state, search_strategy, previous_urls
                )
            else:
                # ê¸°ì¡´ ë°©ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                result = _handle_general_recipe_search(query, rewrite_query, state)

        # ê²€ìƒ‰ ì™„ë£Œ í›„ íˆìŠ¤í† ë¦¬ ì €ì¥ (ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ)
        try:
            recipe_results = result.get("recipe", {}).get("results")
            if recipe_results:
                logger.info(f"íˆìŠ¤í† ë¦¬ ì €ì¥ ëŒ€ìƒ ë ˆì‹œí”¼: {len(recipe_results)}ê°œ")

                # URL ì •ë³´ ë¡œê¹…
                for i, r in enumerate(recipe_results[:3]):
                    logger.info(f"  {i+1}. {r.get('title', 'No title')[:30]}... | URL: {r.get('url', 'No URL')[:50]}...")

                search_context_to_save = {
                    "query_type": "specific_dish",  # LLMìœ¼ë¡œ ê°œì„  ê°€ëŠ¥
                    "original_query": query,
                    "search_query": rewrite_query or query,
                    "results": [
                        {"title": r.get("title", ""), "url": r.get("url", "")}
                        for r in recipe_results[:3]  # ì²˜ìŒ 3ê°œë§Œ ì €ì¥
                    ],
                    "search_type": "alternative" if is_alternative_search else "initial"
                }

                logger.info(f"ì €ì¥í•  íˆìŠ¤í† ë¦¬ ê²°ê³¼: {len(search_context_to_save['results'])}ê°œ")
                save_recipe_search_result(state, search_context_to_save)
                logger.info("ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ")
            else:
                logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ì„œ íˆìŠ¤í† ë¦¬ ì €ì¥í•˜ì§€ ì•ŠìŒ")
        except Exception as e:
            logger.warning(f"íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        return result

    except Exception as e:
        logger.error(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±: {e}", exc_info=True)
        # ì™„ì „ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        try:
            if "ì„ íƒëœ ë ˆì‹œí”¼:" in query and "URL:" in query:
                return _handle_selected_recipe(query, state)
            else:
                rewrite_query = state.rewrite.get("text", "")
                return _handle_general_recipe_search(query, rewrite_query, state)
        except Exception as fallback_e:
            logger.error(f"í´ë°±ë„ ì‹¤íŒ¨: {fallback_e}")
            return {
                "recipe": {"results": [], "ingredients": [], "error": str(fallback_e)},
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤, ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }

def _handle_general_recipe_search_with_history(
    original_query: str, rewrite_query: str, state: ChatState,
    search_strategy: Dict[str, Any], previous_urls: List[str]
) -> Dict[str, Any]:
    """íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ (ì¬ê²€ìƒ‰ ì „ìš©)"""
    logger.info(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ ì‹œì‘: ì „ëµ={search_strategy.get('strategy_type', 'unknown')}")

    try:
        user_preferences = {}
        if state and state.user_id:
            user_preferences = get_user_preferences(state.user_id)
            logger.info(f"ì‚¬ìš©ì {state.user_id} ê°œì¸ ì„ í˜¸ë„: {user_preferences}")

        strategy_type = search_strategy.get('strategy_type', 'SAME_DISH_ALTERNATIVE')
        alternative_queries = search_strategy.get('alternative_queries', [])

        if alternative_queries:
            base_query = alternative_queries[0]
            logger.info(f"LLM ìƒì„± ëŒ€ì•ˆ ì¿¼ë¦¬ ì‚¬ìš©: {base_query}")
        else:
            base_query = _extract_recipe_query(original_query, rewrite_query)

        if user_preferences:
            personalized_query, exclusion_keywords = create_personalized_search_keywords(base_query, user_preferences)
            logger.info(f"ê°œì¸ë§ì¶¤í™”ëœ ì¿¼ë¦¬: {personalized_query}")
            recipe_query = personalized_query
        else:
            recipe_query = base_query
            exclusion_keywords = []

        # Tavilyë¡œ ì™¸ë¶€ ë ˆì‹œí”¼ ê²€ìƒ‰ (íˆìŠ¤í† ë¦¬ ê¸°ë°˜)
        recipe_results = _search_with_tavily_filtered(recipe_query, user_preferences, previous_urls)

        # ì¤‘ë³µ URL í•„í„°ë§ ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¶”ê°€ ê²€ìƒ‰
        if len(recipe_results) < 2 and len(alternative_queries) > 1:
            logger.info("ê²°ê³¼ ë¶€ì¡±ìœ¼ë¡œ ì¶”ê°€ ëŒ€ì•ˆ ì¿¼ë¦¬ ê²€ìƒ‰")
            for alt_query in alternative_queries[1:3]:  # 2-3ë²ˆì§¸ ëŒ€ì•ˆ ì¿¼ë¦¬ ì‹œë„
                additional_results = _search_with_tavily_filtered(alt_query, user_preferences, previous_urls)
                recipe_results.extend(additional_results)
                if len(recipe_results) >= 3:
                    break

        if recipe_results:
            personalized_msg = ""
            if user_preferences.get("vegan"):
                personalized_msg = " (ë¹„ê±´ ë ˆì‹œí”¼ ìœ„ì£¼ë¡œ ê²€ìƒ‰ë¨)"
            elif user_preferences.get("allergy") or user_preferences.get("unfavorite"):
                personalized_msg = " (ê°œì¸ ì„ í˜¸ë„ ë°˜ì˜ë¨)"

            strategy_msg = ""
            if strategy_type == "SAME_DISH_ALTERNATIVE":
                strategy_msg = " ë‹¤ë¥¸ ë ˆì‹œí”¼ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤"
            elif strategy_type == "DIFFERENT_MENU":
                strategy_msg = " ìƒˆë¡œìš´ ìš”ë¦¬ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤"

            message = (
                f"{len(recipe_results)}ê°œì˜{strategy_msg}{personalized_msg}.\n\n"
                "ğŸ’¡ ì›í•˜ëŠ” ë ˆì‹œí”¼ë¥¼ í´ë¦­í•˜ì—¬ 'ì¬ë£Œ ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í•„ìš”í•œ ì¬ë£Œë“¤ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!"
            )
        else:
            message = "ìƒˆë¡œìš´ ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."

        logger.info(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ ì™„ë£Œ: {len(recipe_results)}ê°œ ê²°ê³¼")
        return {
            "recipe": {
                "results": recipe_results,
                "ingredients": [],
                "search_query": recipe_query,
                "search_strategy": strategy_type
            },
            "response": message
        }

    except Exception as e:
        logger.error(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±: {e}")
        return _handle_general_recipe_search(original_query, rewrite_query, state)

def _handle_general_recipe_search(original_query: str, rewrite_query: str, state: ChatState = None) -> Dict[str, Any]:
    """Tavily APIë¡œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ê³  ì‚¬ì´ë“œë°”ì— í‘œì‹œí•  URL ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    user_preferences = {}
    if state and state.user_id:
        user_preferences = get_user_preferences(state.user_id)
        logger.info(f"ì‚¬ìš©ì {state.user_id} ê°œì¸ ì„ í˜¸ë„: {user_preferences}")
    
    base_query = _extract_recipe_query(original_query, rewrite_query)
    
    if user_preferences:
        personalized_query, exclusion_keywords = create_personalized_search_keywords(base_query, user_preferences)
        logger.info(f"ê°œì¸ë§ì¶¤í™”ëœ ì¿¼ë¦¬: {personalized_query}")
        logger.info(f"ì œì™¸ í‚¤ì›Œë“œ: {exclusion_keywords}")
        recipe_query = personalized_query
    else:
        recipe_query = base_query
        exclusion_keywords = []
    
    recipe_results = _search_with_tavily(recipe_query, user_preferences)
    
    if recipe_results:
        personalized_msg = ""
        if user_preferences.get("vegan"):
            personalized_msg = " (ë¹„ê±´ ë ˆì‹œí”¼ ìœ„ì£¼ë¡œ ê²€ìƒ‰ë¨)"
        elif user_preferences.get("allergy") or user_preferences.get("unfavorite"):
            personalized_msg = " (ê°œì¸ ì„ í˜¸ë„ ë°˜ì˜ë¨)"
            
        message = (
            f"{len(recipe_results)}ê°œì˜ ë ˆì‹œí”¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤{personalized_msg}.\n\n"
            "ğŸ’¡ ì›í•˜ëŠ” ë ˆì‹œí”¼ë¥¼ í´ë¦­í•˜ì—¬ 'ì¬ë£Œ ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í•„ìš”í•œ ì¬ë£Œë“¤ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!"
        )
    else:
        message = "ê´€ë ¨ ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."

    return {
        "recipe": {
            "results": recipe_results, 
            "ingredients": [],
            "search_query": recipe_query
        },
        "response": message
    }


def _handle_selected_recipe(query: str, state: ChatState = None) -> Dict[str, Any]:
    """ì„ íƒëœ ë ˆì‹œí”¼ URLì„ í¬ë¡¤ë§í•˜ê³ , ì¬ë£Œë¥¼ ì¶”ì¶œí•˜ì—¬ DB ìƒí’ˆê³¼ ë§¤í•‘í•©ë‹ˆë‹¤."""
    
    user_preferences = {}
    if state and state.user_id:
        user_preferences = get_user_preferences(state.user_id)
        logger.info(f"ì‚¬ìš©ì {state.user_id} ê°œì¸ ì„ í˜¸ë„: {user_preferences}")
    
    recipe_url = _extract_recipe_url(query)
    if not recipe_url:
        logger.info("ë ˆì‹œí”¼ URLì„ ì°¾ì§€ ëª»í•¨")
        return {
            "recipe": {"results": [], "ingredients": []},
            "response": "ë ˆì‹œí”¼ URLì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¬ë£Œë¥¼ ì¶”ì²œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    
    structured_content = _scrape_and_structure_recipe(recipe_url)
    if not structured_content or not structured_content.get("ingredients"):
        logger.info("ë ˆì‹œí”¼ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŒ")
        return {
            "recipe": {"results": [], "ingredients": []},
            "response": "ë ˆì‹œí”¼ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ì–´ ì¬ë£Œ ì¶”ì²œì´ ì–´ë µìŠµë‹ˆë‹¤."
        }
    
    logger.info(f"ë ˆì‹œí”¼ êµ¬ì¡°í™” ì™„ë£Œ: {structured_content.get('title', 'ì œëª© ì—†ìŒ')}")
    
    extracted_ingredients = structured_content.get("ingredients", [])
    
    if user_preferences:
        filtered_ingredients = filter_recipe_ingredients(extracted_ingredients, user_preferences)
        logger.info(f"ê°œì¸ë§ì¶¤í™” í•„í„°ë§: {len(extracted_ingredients)} -> {len(filtered_ingredients)}")
        extracted_ingredients = filtered_ingredients
        
        structured_content["ingredients"] = extracted_ingredients
    
    additional_keywords = []
    if state and state.rewrite.get("keywords"):
        filtered_keywords = [
            k for k in state.rewrite["keywords"] 
            if k not in ['ì¬ë£Œ', 'êµ¬ë§¤', 'ìƒí’ˆ', 'ì¶”ì²œ', 'ì‡¼í•‘ëª°']
        ]
        additional_keywords.extend(filtered_keywords)
    
    all_search_terms = list(set(extracted_ingredients + additional_keywords))
    logger.info(f"DB ê²€ìƒ‰ í‚¤ì›Œë“œ: {all_search_terms}")
    
    matched_products = _get_product_details_from_db(all_search_terms, user_preferences, state)  # hjs ìˆ˜ì • # ë©€í‹°í„´ ê¸°ëŠ¥
    
    formatted_recipe_message = _format_recipe_content(structured_content, user_preferences)
    
    logger.info(f"ë ˆì‹œí”¼ ì²˜ë¦¬ ì™„ë£Œ: ì¬ë£Œ {len(all_search_terms)}ê°œ, ì¶”ì²œ ìƒí’ˆ {len(matched_products)}ê°œ")
    # print("recipe_search.py matched_products:",matched_products)
    # print("recipe_search.py formatted_recipe_message:",formatted_recipe_message)
    # print("recipe_search.py structured_content:",structured_content)
    return {
        "recipe": {
            "results": [],
            "ingredients": matched_products,
            "selected_recipe": structured_content
        },
        "meta": {
            "final_message": formatted_recipe_message 
        }
    }

def _get_product_details_from_db(
    ingredient_names: List[str],
    user_preferences: Dict[str, Any] = None,
    state: Optional[ChatState] = None
) -> List[Dict[str, Any]]:
    """ìƒí’ˆ ê²€ìƒ‰ ë…¸ë“œë¥¼ í™œìš©í•´ ë ˆì‹œí”¼ ì¬ë£Œì— ë§ëŠ” ìƒí’ˆì„ ì¡°íšŒí•©ë‹ˆë‹¤."""  # hjs ìˆ˜ì • # ë©€í‹°í„´ ê¸°ëŠ¥
    if not ingredient_names:
        return []

    search_engine = get_search_engine()

    aggregated_products: List[Dict[str, Any]] = []
    seen_products: set = set()

    # hjs ìˆ˜ì •: ì¤‘ë³µ ì œê±° ë° ë³‘ë ¬ ê²€ìƒ‰ ì¤€ë¹„
    normalized_terms: List[str] = []
    seen_terms = set()
    for raw_term in ingredient_names:
        term = (raw_term or "").strip()
        if term and term not in seen_terms:
            seen_terms.add(term)
            normalized_terms.append(term)

    if not normalized_terms:
        return []

    base_user_id = state.user_id if state and state.user_id else 'anonymous'
    base_session_id = state.session_id if state else None
    history_tail = state.conversation_history[-6:] if state and state.conversation_history else []

    CHUNK_SIZE = 3  # í•œ ë²ˆì˜ ê²€ìƒ‰ì— ì‚¬ìš©í•  ì¬ë£Œ ìˆ˜ (hjs ìˆ˜ì •)
    MAX_WORKERS = min(4, max(1, len(normalized_terms)))

    def _chunk_terms(seq: List[str], size: int) -> List[List[str]]:
        return [seq[i:i + size] for i in range(0, len(seq), size)]

    def _run_chunk(chunk_terms: List[str]) -> List[Dict[str, Any]]:
        query = " ".join(chunk_terms)
        temp_state = ChatState(user_id=base_user_id, session_id=base_session_id)
        temp_state.query = query
        temp_state.route = {"target": "product_search"}
        temp_state.rewrite = {"text": query, "keywords": chunk_terms}
        temp_state.slots = {"product": chunk_terms[0], "item": chunk_terms[0]}
        temp_state.search = {}
        temp_state.conversation_history = history_tail

        try:
            search_result = search_engine.search_products(temp_state)
        except Exception as err:
            logger.warning(f"ë ˆì‹œí”¼ ì—°ë™ ìƒí’ˆ ê²€ìƒ‰ ì‹¤íŒ¨ (terms={chunk_terms}): {err}")
            return []

        if not search_result.get("success") or not search_result.get("candidates"):
            return []

        return search_result["candidates"]

    chunks = _chunk_terms(normalized_terms, CHUNK_SIZE)

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_chunk = {executor.submit(_run_chunk, chunk): chunk for chunk in chunks}
        for future in as_completed(future_to_chunk):
            try:
                candidates = future.result()
            except Exception as err:
                logger.warning(f"ë³‘ë ¬ ìƒí’ˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {err}")
                continue

            for candidate in candidates:
                name = candidate.get("name") or candidate.get("sku") or ""
                if not name or name in seen_products:
                    continue
                if not _passes_user_preferences(name, user_preferences):
                    continue

                aggregated_products.append({
                    'name': name,
                    'price': float(candidate.get('price') or 0.0),
                    'origin': candidate.get('origin') or 'ì •ë³´ ì—†ìŒ',
                    'organic': bool(candidate.get('organic')) if candidate.get('organic') is not None else False
                })
                seen_products.add(name)

                if len(aggregated_products) >= 15:
                    break

            if len(aggregated_products) >= 15:
                break

    if aggregated_products:
        logger.info(f"ìƒí’ˆ ê²€ìƒ‰ ì—”ì§„ ê¸°ë°˜ ì¶”ì²œ {len(aggregated_products)}ê°œ í™•ë³´")  # hjs ìˆ˜ì • # ë©€í‹°í„´ ê¸°ëŠ¥
        return aggregated_products

    logger.info("ìƒí’ˆ ê²€ìƒ‰ ì—”ì§„ ê²°ê³¼ ì—†ìŒ, ê¸°ì¡´ DB ì¡°íšŒ í´ë°± ìˆ˜í–‰")  # hjs ìˆ˜ì • # ë©€í‹°í„´ ê¸°ëŠ¥
    return _legacy_product_details_lookup(ingredient_names, user_preferences)


def _passes_user_preferences(product_name: str, user_preferences: Optional[Dict[str, Any]]) -> bool:
    """ì‚¬ìš©ì ì„ í˜¸/ì œì•½ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""  # hjs ìˆ˜ì • # ë©€í‹°í„´ ê¸°ëŠ¥
    if not user_preferences:
        return True

    lowered = product_name.lower()

    if user_preferences.get("vegan", False):
        vegan_exclusions = [
            "ê³ ê¸°", "ë¼ì§€", "ì†Œê³ ê¸°", "ë‹­", "ìƒì„ ", "ìƒˆìš°", "ì˜¤ì§•ì–´",
            "ê³„ë€", "ë‹¬ê±€", "ìš°ìœ ", "ì¹˜ì¦ˆ", "ë²„í„°", "ìš”êµ¬ë¥´íŠ¸", "ë² ì´ì»¨",
            "í–„", "ì†Œì‹œì§€", "ì°¸ì¹˜", "ì—°ì–´", "ë©¸ì¹˜", "ì “ê°ˆ"
        ]
        if any(exclusion in lowered for exclusion in vegan_exclusions):
            return False

    if user_preferences.get("allergy"):
        allergy_items = [item.strip().lower() for item in user_preferences["allergy"].split(",") if item.strip()]
        if any(allergen and allergen in lowered for allergen in allergy_items):
            return False

    if user_preferences.get("unfavorite"):
        unfavorite_items = [item.strip().lower() for item in user_preferences["unfavorite"].split(",") if item.strip()]
        if any(unfavorite and unfavorite in lowered for unfavorite in unfavorite_items):
            return False

    return True


def _legacy_product_details_lookup(ingredient_names: List[str], user_preferences: Dict[str, Any] = None) -> List[Dict[str, Any]]:
    """ê¸°ì¡´ SQL ê¸°ë°˜ ìƒí’ˆ ì¡°íšŒ (í´ë°±ìš©)."""  # hjs ìˆ˜ì • # ë©€í‹°í„´ ê¸°ëŠ¥
    conn = get_db_connection()
    if not conn:
        return []

    try:
        with conn.cursor(dictionary=True) as cursor:
            exclusion_conditions = []

            if user_preferences:
                if user_preferences.get("vegan", False):
                    vegan_exclusions = [
                        "ê³ ê¸°", "ë¼ì§€", "ì†Œê³ ê¸°", "ë‹­", "ìƒì„ ", "ìƒˆìš°", "ì˜¤ì§•ì–´",
                        "ê³„ë€", "ë‹¬ê±€", "ìš°ìœ ", "ì¹˜ì¦ˆ", "ë²„í„°", "ìš”êµ¬ë¥´íŠ¸", "ë² ì´ì»¨",
                        "í–„", "ì†Œì‹œì§€", "ì°¸ì¹˜", "ì—°ì–´", "ë©¸ì¹˜", "ì “ê°ˆ"
                    ]
                    for exclusion in vegan_exclusions:
                        exclusion_conditions.append(f"p.product NOT LIKE '%{exclusion}%'")
                    logger.info("ë¹„ê±´ ì‚¬ìš©ì - ë™ë¬¼ì„± ì œí’ˆ ì œì™¸ ì¡°ê±´ ì¶”ê°€")

                if user_preferences.get("allergy"):
                    allergy_items = [item.strip() for item in user_preferences["allergy"].split(",")]
                    for allergy in allergy_items:
                        exclusion_conditions.append(f"p.product NOT LIKE '%{allergy}%'")
                    logger.info(f"ì•ŒëŸ¬ì§€ ì œì™¸ ì¡°ê±´ ì¶”ê°€: {allergy_items}")

                if user_preferences.get("unfavorite"):
                    unfavorite_items = [item.strip() for item in user_preferences["unfavorite"].split(",")]
                    for unfavorite in unfavorite_items:
                        exclusion_conditions.append(f"p.product NOT LIKE '%{unfavorite}%'")
                    logger.info(f"ì„ í˜¸ë„ ì œì™¸ ì¡°ê±´ ì¶”ê°€: {unfavorite_items}")

            where_clauses = ' OR '.join(['p.product LIKE %s'] * len(ingredient_names))

            exclusion_clause = ""
            if exclusion_conditions:
                exclusion_clause = " AND " + " AND ".join(exclusion_conditions)

            sql = f"""
                SELECT p.product as name, p.unit_price as price, p.origin, p.organic
                FROM product_tbl p
                WHERE ({where_clauses}){exclusion_clause}
                LIMIT 15
            """

            params = [f"%{name}%" for name in ingredient_names]

            cursor.execute(sql, params)
            products = cursor.fetchall()

            formatted_products = []
            for p in products:
                formatted_products.append({
                    'name': p.get('name', ''),
                    'price': float(p.get('price', 0.0)),
                    'origin': p.get('origin', 'ì •ë³´ ì—†ìŒ'),
                    'organic': True if p.get('organic') == 'Y' else False
                })

            logger.info(f"í´ë°± DB ì¡°íšŒ ê²°ê³¼: {len(formatted_products)}ê°œ ìƒí’ˆ")
            return formatted_products

    except Error as e:
        logger.error(f"ìƒí’ˆ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    finally:
        if conn and conn.is_connected():
            conn.close()

def _is_crawlable_url(url: str) -> bool:
    """URLì´ í¬ë¡¤ë§ ê°€ëŠ¥í•œì§€ ê°„ë‹¨íˆ íŒë‹¨í•©ë‹ˆë‹¤."""
    from urllib.parse import urlparse
    
    try:
        parsed = urlparse(url.lower())
        domain = parsed.netloc.replace('www.', '')
        
        excluded_patterns = ['youtube.', 'youtu.be', 'instagram.', 'facebook.', 'tiktok.', 'pinterest.']
        if any(pattern in domain for pattern in excluded_patterns):
            return False
        
        path = parsed.path.lower()
        if path.endswith(('.mp4', '.avi', '.mov', '.pdf', '.jpg', '.png', '.gif')):
            return False
            
        return True
        
    except Exception:
        return False

def _quick_validate_url(url: str) -> bool:
    """URLì´ ì‹¤ì œë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.head(url, headers=headers, timeout=3)
        
        if 200 <= response.status_code < 300:
            content_type = response.headers.get('content-type', '').lower()
            return 'text/html' in content_type
            
        return False
    except Exception:
        return False

def _search_with_tavily_filtered(query: str, user_preferences: Dict[str, Any] = None, exclude_urls: List[str] = None) -> List[Dict[str, Any]]:
    """íˆìŠ¤í† ë¦¬ ê¸°ë°˜ Tavily ê²€ìƒ‰ (ì´ì „ ê²°ê³¼ ì œì™¸)"""
    exclude_urls = exclude_urls or []

    try:
        from tavily import TavilyClient
        client = TavilyClient(api_key=TAVILY_API_KEY)

        logger.info(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ Tavily ê²€ìƒ‰ ì‹¤í–‰: '{query}' (ì œì™¸ URL: {len(exclude_urls)}ê°œ)")

        exclusion_terms = ["-youtube", "-instagram", "-facebook", "-tiktok", "-blog.naver.com"]

        if user_preferences:
            if user_preferences.get("vegan", False):
                meat_exclusions = ["-ê³ ê¸°", "-ë¼ì§€ê³ ê¸°", "-ì†Œê³ ê¸°", "-ë‹­ê³ ê¸°", "-ìƒì„ ", "-ìœ¡ë¥˜"]
                exclusion_terms.extend(meat_exclusions)
                logger.info("ë¹„ê±´ ì‚¬ìš©ì - ìœ¡ë¥˜ ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ ì œì™¸")

            if user_preferences.get("allergy"):
                allergy_items = user_preferences["allergy"].split(",")
                for item in allergy_items:
                    exclusion_terms.append(f"-{item.strip()}")
                logger.info(f"ì•ŒëŸ¬ì§€ ê¸°ë°˜ ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€: {allergy_items}")

            if user_preferences.get("unfavorite"):
                unfavorite_items = user_preferences["unfavorite"].split(",")
                for item in unfavorite_items:
                    exclusion_terms.append(f"-{item.strip()}")
                logger.info(f"ì„ í˜¸ë„ ê¸°ë°˜ ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€: {unfavorite_items}")

        enhanced_query = f"{query} ë ˆì‹œí”¼ {' '.join(exclusion_terms)}"

        search_result = client.search(
            query=enhanced_query,
            search_depth="basic",
            max_results=30
        )

        search_results_list = search_result.get("results", [])
        random.shuffle(search_results_list)

        validated_results = []

        for res in search_results_list:
            url = res.get("url", "")

            if url in exclude_urls:
                logger.info(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ URL ì œì™¸: {url[:50]}...")
                continue

            if not url or not _is_crawlable_url(url):
                continue

            if not _quick_validate_url(url):
                logger.info(f"ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ URL ì œì™¸: {url}")
                continue

            if user_preferences and should_exclude_recipe_content(
                res.get("title", ""), res.get("content", ""), user_preferences
            ):
                logger.info(f"ê°œì¸ ì„ í˜¸ë„ì— ì˜í•´ ì œì™¸ëœ ë ˆì‹œí”¼: {res.get('title', 'Unknown')}")
                continue

            original_title = res.get("title", "ì œëª© ì—†ìŒ")
            content = res.get("content", "")

            title = original_title[:30] + ("..." if len(original_title) > 30 else "")
            description = content[:150]

            if openai_client and (original_title or content):
                try:
                    if original_title:
                        title_response = openai_client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "ë‹¤ìŒ ë ˆì‹œí”¼ ì œëª©ì„ 30ê¸€ì ë‚´ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì¤˜. ì˜ˆì‹œ: 'ìì·¨ìƒë„ ì‰½ê²Œ ë§Œë“œëŠ” ì´ˆê°„ë‹¨ ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼' / 'ìê¾¸ ë•¡ê¸°ëŠ” ë§ˆì•½ì–‘ë…ì˜ ë§¤ì½¤í•œ ë‹­ë³¶ìŒíƒ• ì¡°ë¦¬ë²•"},
                                {"role": "user", "content": f"ì œëª© ìš”ì•½: {original_title}"}
                            ],
                            temperature=0.1, max_tokens=20
                        )
                        title_summary = title_response.choices[0].message.content.strip()
                        
                        title_summary = title_summary.strip('"').strip("'")
                        title = title_summary[:30] + ("..." if len(title_summary) > 30 else "")

                    if content:
                        desc_response = openai_client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "ë‹¤ìŒ ë ˆì‹œí”¼ ë‚´ìš©ì„ 20~30ê¸€ìë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì¤˜. ë‹µë³€ ì˜ˆì‹œ 1: ê¹€ì¹˜Â·ì°¸ì¹˜ ë³¶ì•„ ë‘ë¶€ ì˜¬ë¦° ë§¤ì½¤ì°Œê°œ ì™„ì„±. ë‹µë³€ ì˜ˆì‹œ 2: ë‹­ê³ ê¸° ë°ì³ ì±„ì†Œ ë„£ê³  ë§¤ì½¤í•˜ê²Œ ë“ì¸ ë‹­ë³¶ìŒíƒ•"},
                                {"role": "user", "content": f"ìš”ì•½: {content[:300]}"}
                            ],
                            temperature=0.1, max_tokens=30
                        )
                        desc_summary = desc_response.choices[0].message.content.strip()
                        description = desc_summary[:30] + ("..." if len(desc_summary) > 30 else "")
                except Exception:
                    pass

            validated_results.append({
                "title": title,
                "url": url,
                "description": description
            })

            if len(validated_results) >= 3:
                break

        logger.info(f"íˆìŠ¤í† ë¦¬ í•„í„°ë§ëœ ë ˆì‹œí”¼ URL: {len(validated_results)}ê°œ (ì œì™¸ëœ URL: {len(exclude_urls)}ê°œ)")
        return validated_results

    except Exception as e:
        logger.error(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ Tavily ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def _search_with_tavily(query: str, user_preferences: Dict[str, Any] = None) -> List[Dict[str, Any]]:
    """Tavily APIë¡œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ê³ , ê²°ê³¼ë¥¼ ì„ì€ í›„ ê²€ì¦í•©ë‹ˆë‹¤."""
    try:
        from tavily import TavilyClient
        client = TavilyClient(api_key=TAVILY_API_KEY)
        
        logger.info(f"Tavily ê²€ìƒ‰ ì‹¤í–‰: '{query}'")
        
        exclusion_terms = ["-youtube", "-instagram", "-facebook", "-tiktok", "-blog.naver.com", "-m.blog.naver.com"]

        if user_preferences:
            if user_preferences.get("vegan", False):
                meat_exclusions = ["-ê³ ê¸°", "-ë¼ì§€ê³ ê¸°", "-ì†Œê³ ê¸°", "-ë‹­ê³ ê¸°", "-ìƒì„ ", "-ìœ¡ë¥˜"]
                exclusion_terms.extend(meat_exclusions)
                logger.info("ë¹„ê±´ ì‚¬ìš©ì - ìœ¡ë¥˜ ê´€ë ¨ ê²€ìƒ‰ ê²°ê³¼ ì œì™¸")

            if user_preferences.get("allergy"):
                allergy_items = user_preferences["allergy"].split(",")
                for item in allergy_items:
                    exclusion_terms.append(f"-{item.strip()}")
                logger.info(f"ì•ŒëŸ¬ì§€ ê¸°ë°˜ ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€: {allergy_items}")

            if user_preferences.get("unfavorite"):
                unfavorite_items = user_preferences["unfavorite"].split(",")
                for item in unfavorite_items:
                    exclusion_terms.append(f"-{item.strip()}")
                logger.info(f"ì„ í˜¸ë„ ê¸°ë°˜ ì œì™¸ í‚¤ì›Œë“œ ì¶”ê°€: {unfavorite_items}")
        
        enhanced_query = f"{query} ë ˆì‹œí”¼ {' '.join(exclusion_terms)}"
        
        search_result = client.search(
            query=enhanced_query,
            search_depth="basic",
            max_results=20 
        )
        
        search_results_list = search_result.get("results", [])
        random.shuffle(search_results_list)

        validated_results = []
        
        for res in search_results_list:
            url = res.get("url", "")
            
            if not url or not _is_crawlable_url(url):
                continue
            
            if not _quick_validate_url(url):
                logger.info(f"ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ URL ì œì™¸: {url}")
                continue
            
            if user_preferences and should_exclude_recipe_content(
                res.get("title", ""), res.get("content", ""), user_preferences
            ):
                logger.info(f"ê°œì¸ ì„ í˜¸ë„ì— ì˜í•´ ì œì™¸ëœ ë ˆì‹œí”¼: {res.get('title', 'Unknown')}")
                continue
            
            original_title = res.get("title", "ì œëª© ì—†ìŒ")
            content = res.get("content", "")
            
            title = original_title[:30] + ("..." if len(original_title) > 30 else "")
            description = content[:150]
            
            if openai_client and (original_title or content):
                try:
                    if original_title:
                        title_response = openai_client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "ë‹¤ìŒ ë ˆì‹œí”¼ ì œëª©ì„ 30ê¸€ì ë‚´ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì¤˜. ì˜ˆì‹œ: 'ìì·¨ìƒë„ ì‰½ê²Œ ë§Œë“œëŠ” ì´ˆê°„ë‹¨ ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼' / 'ìê¾¸ ë•¡ê¸°ëŠ” ë§ˆì•½ì–‘ë…ì˜ ë§¤ì½¤í•œ ë‹­ë³¶ìŒíƒ• ì¡°ë¦¬ë²•"},
                                {"role": "user", "content": f"ì œëª© ìš”ì•½: {original_title}"}
                            ],
                            temperature=0.1, max_tokens=20
                        )
                        title_summary = title_response.choices[0].message.content.strip()
                        title_summary = title_summary.strip('"').strip("'")
                        title = title_summary[:30] + ("..." if len(title_summary) > 30 else "")
                    
                    if content:
                        desc_response = openai_client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "ë‹¤ìŒ ë ˆì‹œí”¼ ë‚´ìš©ì„ 20~30ê¸€ìë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì¤˜. ë‹µë³€ ì˜ˆì‹œ 1: ê¹€ì¹˜Â·ì°¸ì¹˜ ë³¶ì•„ ë‘ë¶€ ì˜¬ë¦° ë§¤ì½¤ì°Œê°œ ì™„ì„±. ë‹µë³€ ì˜ˆì‹œ 2: ë‹­ê³ ê¸° ë°ì³ ì±„ì†Œ ë„£ê³  ë§¤ì½¤í•˜ê²Œ ë“ì¸ ë‹­ë³¶ìŒíƒ•"},
                                {"role": "user", "content": f"ìš”ì•½: {content[:300]}"}
                            ],
                            temperature=0.1, max_tokens=30
                        )
                        desc_summary = desc_response.choices[0].message.content.strip()
                        description = desc_summary[:30] + ("..." if len(desc_summary) > 30 else "")
                except Exception:
                    pass

            validated_results.append({
                "title": title,
                "url": url,
                "description": description            
            })
            
            if len(validated_results) >= 3:
                break
        
        logger.info(f"ê²€ì¦ëœ ë ˆì‹œí”¼ URL: {len(validated_results)}ê°œ")
        return validated_results
        
    except Exception as e:
        logger.error(f"Tavily ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def _scrape_and_structure_recipe(url: str) -> Optional[Dict[str, Any]]:
    """URLì„ í¬ë¡¤ë§í•˜ê³  LLMì„ ì‚¬ìš©í•´ ë‚´ìš©ì„ êµ¬ì¡°í™”í•©ë‹ˆë‹¤."""
    logger.info(f"URL í¬ë¡¤ë§ ë° ë¶„ì„ ì‹œì‘: {url}")
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        page_text = soup.get_text(separator='\n', strip=True)
        
        if not openai_client:
            logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ ë ˆì‹œí”¼ êµ¬ì¡°í™” ë¶ˆê°€.")
            return None
            
        return _llm_extract_recipe_content(page_text[:4000])

    except Exception as e:
        logger.error(f"URL í¬ë¡¤ë§ ë° êµ¬ì¡°í™” ì‹¤íŒ¨ {url}: {e}")
        return None

def _extract_recipe_query(original_query: str, rewrite_query: str = "") -> str:
    """ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ ë ˆì‹œí”¼ëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not openai_client:
        return f"{original_query} ë ˆì‹œí”¼"

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ìš”ë¦¬ ì´ë¦„ë§Œ ì¶”ì¶œí•´ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ 'ê¹€ì¹˜ì°Œê°œ ë§›ìˆê²Œ ë“ì´ëŠ” ë²• ì•Œë ¤ì¤˜' -> 'ê¹€ì¹˜ì°Œê°œ'"},
                {"role": "user", "content": f"ì›ë³¸: '{original_query}', ì¬ì‘ì„±: '{rewrite_query}'"}
            ],
            temperature=0.1, max_tokens=50
        )
        return response.choices[0].message.content.strip().strip('"')
    except Exception as e:
        logger.error(f"LLM ì¿¼ë¦¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return f"{original_query} ë ˆì‹œí”¼"

def _get_all_items_from_db() -> List[str]:
    """DBì—ì„œ ëª¨ë“  í’ˆëª©ëª…(item)ì„ ê°€ì ¸ì™€ì„œ ì¤‘ë³µ ì œê±°ëœ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    conn = get_db_connection()
    if not conn:
        logger.warning("DB ì—°ê²° ì‹¤íŒ¨ë¡œ í’ˆëª©ëª…ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    try:
        with conn.cursor() as cursor:
            sql = "SELECT DISTINCT item FROM product_tbl WHERE item IS NOT NULL ORDER BY item"
            cursor.execute(sql)
            items = [row[0] for row in cursor.fetchall()]
            logger.info(f"DBì—ì„œ {len(items)}ê°œì˜ í’ˆëª©ëª…ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
            return items
    except Error as e:
        logger.error(f"í’ˆëª©ëª… ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    finally:
        if conn and conn.is_connected():
            conn.close()

def _llm_extract_recipe_content(page_text: str) -> Dict[str, Any]:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤."""
    
    db_items = _get_all_items_from_db()
    db_items_str = ", ".join(db_items) if db_items else "í’ˆëª© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
    
    system_prompt = f"""ë‹¹ì‹ ì€ ì‹ ì„ ì‹í’ˆ ì‡¼í•‘ëª°ì„ ìœ„í•œ ë ˆì‹œí”¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ê³ ê°ì—ê²Œ í•„ìš”í•œ ì¬ë£Œë¥¼ ì¶”ì²œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

**ğŸ” DB í’ˆëª© ì°¸ì¡° ë°ì´í„°:**
{{{db_items_str}}}

**ì¶”ì¶œ ê·œì¹™:**
1. **title**: ìš”ë¦¬ì˜ ì •í™•í•œ ì´ë¦„ (ì˜ˆ: "ê¹€ì¹˜ì°Œê°œ", "ë³¶ìŒë°¥")
2. **ingredients**: ì‡¼í•‘ëª°ì—ì„œ êµ¬ë§¤ ê°€ëŠ¥í•œ ì‹ ì„ ì‹í’ˆ ì¬ë£Œë§Œ ì¶”ì¶œ
## ê¸°ë³¸ ì›ì¹™
ì¬ë£Œì˜ **í•µì‹¬ ëª…ì‚¬ í˜•íƒœ**ë¡œ í‘œì¤€í™”í•©ë‹ˆë‹¤.
ì˜ˆ: 'ëŒ€íŒŒ', 'ì–‘íŒŒ', 'ë¼ì§€ê³ ê¸°'
---
## 1ë‹¨ê³„: ë³µí•©ì–´ ë¶„í•´
**ë³µí•©ì–´ë¥¼ ë°˜ë“œì‹œ ë¶„í•´í•˜ì—¬ ê¸°ë³¸ ì¬ë£Œë§Œ ì¶”ì¶œí•˜ì„¸ìš”**
**ë¶„í•´ ì˜ˆì‹œ:**
- 'ì‹ ê¹€ì¹˜' â†’ 'ê¹€ì¹˜' (ì‹ ì„ ë„ í‘œí˜„ ì œê±°)
- 'ë‹¤ì§„ë§ˆëŠ˜' â†’ 'ë§ˆëŠ˜' (ì¡°ë¦¬ ìƒíƒœ ì œê±°)
- 'ë³¶ì€ê¹¨' â†’ 'ê¹¨' (ì¡°ë¦¬ë²• ì œê±°)
- 'ìœ¼ê¹¬ê°ì' â†’ 'ê°ì' (ì¡°ë¦¬ ìƒíƒœ ì œê±°)
- 'ì¬ì–‘íŒŒ' â†’ 'ì–‘íŒŒ' (ì°ê¸° ë°©ë²• ì œê±°)
- 'ë°ì¹œì‹œê¸ˆì¹˜' â†’ 'ì‹œê¸ˆì¹˜' (ì „ì²˜ë¦¬ ì œê±°)

**ë¶„í•´ ì›ì¹™:**

**ì œê±°í•´ì•¼ í•  ìˆ˜ì‹ì–´ë“¤:**
- í˜•ìš©ì‚¬/ê´€í˜•ì–´: ì‹ ì„ í•œ, ë‹¤ì§„, ì¬, ë°ì¹œ, ë³¶ì€, ìœ¼ê¹¬ ë“±
- ì¡°ë¦¬ë²•: ë³¶ìŒ, ë¬´ì¹¨, ì ˆì„ ë“±
- ìƒíƒœ í‘œí˜„: ìµì€, ìƒ, ë§ˆë¥¸, ì –ì€ ë“±
- í¬ê¸°/í˜•íƒœ: í°, ì‘ì€, ì–‡ì€, ë‘êº¼ìš´ ë“±

**íŠ¹ìˆ˜ ì¼€ì´ìŠ¤:**
- "í’‹ê³ ì¶”" â†’ "ê³ ì¶”"
- "ì• í˜¸ë°•" â†’ "í˜¸ë°•"
- "ìƒˆìš°ì “" â†’ "ìƒˆìš°"

**í•µì‹¬**: í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œ ë³´ì´ë”ë¼ë„ ë°˜ë“œì‹œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ì„¸ìš”
---
## 2ë‹¨ê³„: DB í’ˆëª©ëª… í‘œì¤€í™”

**ë¶„í•´ëœ ì¬ë£Œë¥¼ DB í’ˆëª© ì°¸ì¡° ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ í‘œì¤€í™”í•˜ì„¸ìš”**

**DB í‘œì¤€í™” ì˜ˆì‹œ:**
- 'ê³„ë€' â†’ 'ë‹¬ê±€' (DBì— ìˆëŠ” ì •í™•í•œ í’ˆëª©ëª… ì‚¬ìš©)
- 'ì‚¼ê²¹ì‚´', 'ëª©ì‚´', 'ê°ˆë¹„ì‚´' â†’ 'ë¼ì§€ê³ ê¸°' (DBì— 'ë¼ì§€ê³ ê¸°'ë¡œ í†µí•©)
- 'ì¹˜í‚¨', 'ë‹­ë‹¤ë¦¬', 'ë‹­ê°€ìŠ´ì‚´' â†’ 'ë‹­ê³ ê¸°' (DBì— 'ë‹­ê³ ê¸°'ë¡œ í†µí•©)
- 'ìª½íŒŒ', 'íŒŒ' â†’ 'ëŒ€íŒŒ' (DBì— 'ëŒ€íŒŒ'ë¡œ í‘œì¤€í™”)
- 'ì–‘ë°°ì¶”' â†’ 'ë°°ì¶”' (DBì— 'ë°°ì¶”'ë¡œ ë“±ë¡)
- 'ê³ ì¶§ê°€ë£¨', 'ë¹¨ê°„ ê³ ì¶”' â†’ 'ê³ ì¶”' (DBì— 'ê³ ì¶”'ë¡œ í‘œì¤€í™”)
- 'ì²­ê²½ì±„', 'ë¡œë©”ì¸' â†’ 'ìƒì¶”' (DBì— 'ìƒì¶”'ë¡œ ë¶„ë¥˜)

**í‘œì¤€í™” ì›ì¹™:**
1. ë¨¼ì € DB í’ˆëª© ë°ì´í„°ì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ëª…ì¹­ì´ ìˆëŠ”ì§€ í™•ì¸
2. ì¼ì¹˜í•˜ëŠ” ëª…ì¹­ì´ ì—†ìœ¼ë©´ ìœ ì‚¬í•œ ì¹´í…Œê³ ë¦¬ì˜ ëŒ€í‘œ í’ˆëª©ëª…ìœ¼ë¡œ ë§¤í•‘
3. DBì— ì „í˜€ ì—†ëŠ” ì¬ë£ŒëŠ” ì¼ë°˜ì ì¸ ëª…ì¹­ ì‚¬ìš©

---

## ì „ì²´ ì²˜ë¦¬ ì˜ˆì‹œ

**ì…ë ¥ ë ˆì‹œí”¼:**
"ë‹¤ì§„ë§ˆëŠ˜ 2ìª½, ì‹ ê¹€ì¹˜ 200g, ì‚¼ê²¹ì‚´ 300g"

**1ë‹¨ê³„ ì²˜ë¦¬ (ë³µí•©ì–´ ë¶„í•´):**
"ë‹¤ì§„ë§ˆëŠ˜" â†’ "ë§ˆëŠ˜"
"ì‹ ê¹€ì¹˜" â†’ "ê¹€ì¹˜" 
"ì‚¼ê²¹ì‚´" â†’ "ì‚¼ê²¹ì‚´" (ì´ë¯¸ ê¸°ë³¸í˜•)

**2ë‹¨ê³„ ì²˜ë¦¬ (DB í‘œì¤€í™”):**
"ë§ˆëŠ˜" â†’ "ë§ˆëŠ˜" (DBì— ìˆìŒ)
"ê¹€ì¹˜" â†’ "ê¹€ì¹˜" (ì¼ë°˜ ëª…ì¹­ ìœ ì§€)
"ì‚¼ê²¹ì‚´" â†’ "ë¼ì§€ê³ ê¸°" (DB í‘œì¤€ëª…)

**ìµœì¢… ê²°ê³¼:**
["ë§ˆëŠ˜", "ê¹€ì¹˜", "ë¼ì§€ê³ ê¸°"]
---

## ì£¼ì˜ì‚¬í•­
1. ë°˜ë“œì‹œ 1ë‹¨ê³„(ë¶„í•´) â†’ 2ë‹¨ê³„(í‘œì¤€í™”) ìˆœì„œë¡œ ì²˜ë¦¬í•˜ì„¸ìš”
2. ê° ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì§€ ë§ê³  ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•˜ì„¸ìš”
3. ì ˆëŒ€ë¡œ ë³µí•©ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
4. DB í’ˆëª© ë°ì´í„°ì—ì„œ ì •í™•í•œ ëª…ì¹­ì„ ì°¾ì•„ ì‚¬ìš©í•˜ì„¸ìš”

- quantity: ìˆ˜ëŸ‰ì„ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤. ë¶„ìˆ˜('1/2')ëŠ” ì†Œìˆ˜ì (0.5)ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ìˆ˜ëŸ‰ì´ ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ 1ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
- unit: ë‹¨ìœ„ë¥¼ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤. (ì˜ˆ: 'g', 'ê°œ', 'ì»µ', 'T', 't')
- í¬í•¨í•  ê²ƒ: ì‹ ì„ ì‹í’ˆ(ìœ¡ë¥˜, ì±„ì†Œ, ê³¼ì¼), êµ¬ë§¤ ê°€ëŠ¥í•œ ê°€ê³µì‹í’ˆ(ë‘ë¶€, ë©´, í†µì¡°ë¦¼), ì–‘ë…/ì¡°ë¯¸ë£Œ(ê°„ì¥, ëœì¥, ì°¸ê¸°ë¦„, ë‹¤ì§„ ë§ˆëŠ˜)
3. **instructions**: ê³ ê°ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¡°ë¦¬ë²• ìš”ì•½
    - ì´ˆë³´ìë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê° ë‹¨ê³„ë¥¼ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
    - ê° ë‹¨ê³„ëŠ” '\\n'ìœ¼ë¡œ êµ¬ë¶„(ì¤‘ìš”)
    - ì „ë¬¸ ìš©ì–´ë³´ë‹¤ëŠ” ì¼ë°˜ì ì¸ í‘œí˜„ ì‚¬ìš©
    - ê°€ì—´ ì˜¨ë„(ì˜ˆ: ì¤‘ë¶ˆ), ì¡°ë¦¬ ì‹œê°„(ì˜ˆ: 5ë¶„ê°„), êµ¬ì²´ì ì¸ ì–‘(ì˜ˆ: 5g, í•œ ìŠ¤í‘¼) ë“± êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

**ì¶œë ¥ í˜•ì‹:**
ë°˜ë“œì‹œ ë‹¤ìŒ JSON êµ¬ì¡°ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
```json
{{
    "title": "ìš”ë¦¬ëª…",
    "ingredients": ["ì¬ë£Œ1", "ì¬ë£Œ2", "ì¬ë£Œ3"],
    "instructions": "1ë‹¨ê³„ ì„¤ëª…\\n2ë‹¨ê³„ ì„¤ëª…\\n3ë‹¨ê³„ ì„¤ëª…"
}}
```

**ì˜ˆì‹œ:**
ì…ë ¥: "ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼... ë¼ì§€ê³ ê¸° 200g, ê¹€ì¹˜ 300g, ì–‘íŒŒ 1ê°œ, ëŒ€íŒŒ 2ëŒ€, ë‘ë¶€ 1ëª¨..."
ì¶œë ¥:
```json
{{
  "title": "ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ",
  "ingredients": ["ë¼ì§€ê³ ê¸°", "ê¹€ì¹˜", "ë‘ë¶€", "ì–‘íŒŒ", "ëŒ€íŒŒ", "êµ­ê°„ì¥", "ê³ ì¶§ê°€ë£¨"],
  "instructions": "1. ë‹¬êµ° ëƒ„ë¹„ì— ë¼ì§€ê³ ê¸°ë¥¼ 200g ë„£ê³  ì¤‘ë¶ˆì—ì„œ ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ì•½ 3ë¶„ê°„ ë³¶ì•„ì¤ë‹ˆë‹¤.\\n2. ë¼ì§€ê³ ê¸°ê°€ ìµìœ¼ë©´ ê¹€ì¹˜ë¥¼ 300g ë„£ê³  5ë¶„ê°„ í•¨ê»˜ ì¶©ë¶„íˆ ë³¶ì•„ ê¹Šì€ ë§›ì„ ë”í•´ì¤ë‹ˆë‹¤.\\n3. ë¬¼ í•œ ì»µì„ ë¶“ê³  ë“ì–´ì˜¤ë¥´ë©´, êµ­ê°„ì¥ê³¼ ê³ ì¶§ê°€ë£¨ë¥¼ ê°ê° ë°˜ ìŠ¤í‘¼, í•œ ìŠ¤í‘¼ì”© ë„£ê³  ì¤‘ë¶ˆì—ì„œ 10ë¶„ê°„ ë” ë“ì—¬ì¤ë‹ˆë‹¤.\\n4. ë§ˆì§€ë§‰ìœ¼ë¡œ ë‘ë¶€, ì–‘íŒŒ, ëŒ€íŒŒë¥¼ ì˜ê²Œ ì°ì–´ë„£ê³  5ë¶„ê°„ í•œì†Œë” ë” ë“ì—¬ ì™„ì„±í•©ë‹ˆë‹¤."
}}
ì…ë ¥:"ë‹¬ê±€ë³¶ìŒë°¥ ë ˆì‹œí”¼... ì‹ ì„ í•œë‹¬ê±€ 3ê°œ, ì°¬ë°¥ 2ê³µê¸°, ë‹¤ì§„ë‹¹ê·¼ 100g, ë§¤ìš´ì–‘íŒŒ ë°˜ê°œ, ì¬ëŒ€íŒŒ 2ëŒ€, ì§„ê°„ì¥ 2ìŠ¤í‘¼, ì°¸ê¸°ë¦„ 1ìŠ¤í‘¼
ì¶œë ¥
{{
  "title": "ë‹¬ê±€ ë³¶ìŒë°¥",
  "ingredients": ["ë‹¬ê±€", "ìŒ€", "ë‹¹ê·¼", "ì–‘íŒŒ", "ëŒ€íŒŒ", "ê°„ì¥", "ì°¸ê¸°ë¦„"],
  "instructions": "1. ë‹¬ê±€ 3ê°œë¥¼ ê·¸ë¦‡ì— í’€ì–´ì„œ ì†Œê¸ˆ í•œ ê¼¬ì§‘ì„ ë„£ê³  ì˜ ì„ì–´ì¤ë‹ˆë‹¤.\\n2. íŒ¬ì— ê¸°ë¦„ì„ ë‘ë¥´ê³  ë‹¬ê±€ë¬¼ì„ ë„£ì–´ ì “ê°€ë½ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì €ì–´ê°€ë©° ìŠ¤í¬ë¨ë¸”ì„ ë§Œë“­ë‹ˆë‹¤.\\n3. ë‹¹ê·¼ê³¼ ì–‘íŒŒëŠ” ì˜ê²Œ ë‹¤ì ¸ì„œ íŒ¬ì— ë„£ê³  2ë¶„ê°„ ë³¶ì•„ì¤ë‹ˆë‹¤.\\n4. ì°¬ë°¥ 2ê³µê¸°ë¥¼ ë„£ê³  ê°„ì¥ 2ìŠ¤í‘¼, ì°¸ê¸°ë¦„ 1ìŠ¤í‘¼ì„ ë„£ì–´ 3ë¶„ê°„ ë³¶ìŠµë‹ˆë‹¤.\\n5. ë§ˆì§€ë§‰ì— ëŒ€íŒŒì™€ ë‹¬ê±€ì„ ë„£ê³  30ì´ˆê°„ ë” ë³¶ì•„ ì™„ì„±í•©ë‹ˆë‹¤."
}}
ì…ë ¥:"ì‹œê¸ˆì¹˜ë‚˜ë¬¼ ë§Œë“œëŠ”ë²•... ì‹ ì„ í•œì‹œê¸ˆì¹˜ 200g, ë‹¤ì§„ë§ˆëŠ˜ 2ìª½, êµ­ê°„ì¥ 1ìŠ¤í‘¼, ê³ ì†Œí•œì°¸ê¸°ë¦„ 2ìŠ¤í‘¼, í–¥ê¸‹í•œê¹»ì 5ì¥
ì¶œë ¥:
{{
  "title": "ì‹œê¸ˆì¹˜ ë‚˜ë¬¼",
  "ingredients": ["ì‹œê¸ˆì¹˜", "ë§ˆëŠ˜", "ê°„ì¥", "ì°¸ê¸°ë¦„", "ê¹»ì"],
  "instructions": "1. ì‹œê¸ˆì¹˜ 200gì„ ê¹¨ë—ì´ ì”»ì–´ì„œ ë“ëŠ” ë¬¼ì— 30ì´ˆê°„ ë°ì³ì¤ë‹ˆë‹¤.\\n2. ì°¬ë¬¼ì— í—¹ê¶ˆì„œ ë¬¼ê¸°ë¥¼ ê¼­ ì§œë‚¸ í›„ 3-4cm ê¸¸ì´ë¡œ ì°ì–´ì¤ë‹ˆë‹¤.\\n3. ë§ˆëŠ˜ 2ìª½ì„ ê³±ê²Œ ë‹¤ì ¸ì„œ ì¤€ë¹„í•©ë‹ˆë‹¤.\\n4. ì‹œê¸ˆì¹˜ì— ë‹¤ì§„ ë§ˆëŠ˜, ê°„ì¥ 1ìŠ¤í‘¼, ì°¸ê¸°ë¦„ 2ìŠ¤í‘¼ì„ ë„£ê³  ì˜ ë¬´ì³ì¤ë‹ˆë‹¤.\\n5. ê¹»ìì„ ì˜ê²Œ ì°ì–´ì„œ ë§ˆì§€ë§‰ì— ì˜¬ë ¤ ì™„ì„±í•©ë‹ˆë‹¤."
}}
ì…ë ¥:"ì—°ì–´êµ¬ì´ ë ˆì‹œí”¼... ë…¸ë¥´ì›¨ì´ì‚°ì—°ì–´ 300g, ìƒí¼í•œë ˆëª¬ 1ê°œ, ì—‘ìŠ¤íŠ¸ë¼ë²„ì§„ì˜¬ë¦¬ë¸Œì˜¤ì¼ 2ìŠ¤í‘¼, ë‹¤ì§„ë§ˆëŠ˜ 3ìª½, ë°ì¹œë¸Œë¡œì½œë¦¬ 150g
ì¶œë ¥:
{{
  "title": "ì—°ì–´ êµ¬ì´",
  "ingredients": ["ì—°ì–´", "ë ˆëª¬", "ì˜¬ë¦¬ë¸Œì˜¤ì¼", "ë§ˆëŠ˜", "ë¸Œë¡œì½œë¦¬"],
  "instructions": "1. ì—°ì–´ 300gì„ í•œì… í¬ê¸°ë¡œ ì°ì–´ì„œ ì†Œê¸ˆ, í›„ì¶”ë¡œ ë°‘ê°„ì„ í•´ì¤ë‹ˆë‹¤.\\n2. ë§ˆëŠ˜ 3ìª½ì„ í¸ìœ¼ë¡œ ì°ê³  ë ˆëª¬ì€ ë°˜ë‹¬ ëª¨ì–‘ìœ¼ë¡œ ì°ì–´ ì¤€ë¹„í•©ë‹ˆë‹¤.\\n3. íŒ¬ì— ì˜¬ë¦¬ë¸Œì˜¤ì¼ì„ ë‘ë¥´ê³  ì¤‘ì•½ë¶ˆì—ì„œ ë§ˆëŠ˜ì„ 1ë¶„ê°„ ë³¶ì•„ í–¥ì„ ëƒ…ë‹ˆë‹¤.\\n4. ì—°ì–´ë¥¼ ë„£ê³  í•œ ë©´ë‹¹ 3ë¶„ì”© ë…¸ë¦‡í•˜ê²Œ êµ¬ì›Œì¤ë‹ˆë‹¤.\\n5. ë¸Œë¡œì½œë¦¬ë¥¼ ë°ì³ì„œ í•¨ê»˜ ë‹´ê³  ë ˆëª¬ì„ ì˜¬ë ¤ ì™„ì„±í•©ë‹ˆë‹¤."
}}
ì…ë ¥:"ë‹­ê³ ê¸°ì°œ ë§Œë“¤ê¸°... í† ì¢…ë‹­ê³ ê¸° 500g, í°ê°ì 2ê°œ, ë‹¨ë‹¹ê·¼ 1ê°œ, ë§¤ìš´ì–‘íŒŒ 1ê°œ, ì‹œì›í•œëœì¥ 2ìŠ¤í‘¼, ë‹¤ì§„ë§ˆëŠ˜ 5ìª½, ì¬ìƒê°• 1ìª½
ì¶œë ¥:
{{
  "title": "ë‹­ê³ ê¸° ì°œ",
  "ingredients": ["ë‹­ê³ ê¸°", "ê°ì", "ë‹¹ê·¼", "ì–‘íŒŒ", "ëœì¥", "ë§ˆëŠ˜", "ìƒê°•"],
  "instructions": "1. ë‹­ê³ ê¸° 500gì„ ì°¬ë¬¼ì— 30ë¶„ê°„ ë‹´ê°€ í•ë¬¼ì„ ì œê±°í•©ë‹ˆë‹¤.\\n2. ê°ìì™€ ë‹¹ê·¼ì€ í¼ì§í•˜ê²Œ ì°ê³ , ì–‘íŒŒëŠ” 4ë“±ë¶„ìœ¼ë¡œ ì°ì–´ì¤ë‹ˆë‹¤.\\n3. ë§ˆëŠ˜ 5ìª½ê³¼ ìƒê°• 1ìª½ì„ í¸ìœ¼ë¡œ ì°ì–´ ì¤€ë¹„í•©ë‹ˆë‹¤.\\n4. ëƒ„ë¹„ì— ë‹­ê³ ê¸°ë¥¼ ë„£ê³  ë¬¼ì„ ìì‘í•˜ê²Œ ë¶€ì€ í›„ ëœì¥ 2ìŠ¤í‘¼ì„ í’€ì–´ ë„£ìŠµë‹ˆë‹¤.\\n5. ë§ˆëŠ˜, ìƒê°•ì„ ë„£ê³  ì„¼ë¶ˆì—ì„œ ë“ì¸ í›„ ì¤‘ë¶ˆë¡œ ì¤„ì—¬ 20ë¶„ê°„ ë“ì…ë‹ˆë‹¤.\\n6. ê°ì, ë‹¹ê·¼, ì–‘íŒŒë¥¼ ë„£ê³  15ë¶„ê°„ ë” ë“ì—¬ ì™„ì„±í•©ë‹ˆë‹¤."
}}
ì…ë ¥:"ë¼ì§€ê³ ê¸°ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼... ì‚¼ê²¹ì‚´ 200g, ì‹ ê¹€ì¹˜ 300g, ë¶€ë“œëŸ¬ìš´ë‘ë¶€ 1ëª¨, ë§¤ìš´ì–‘íŒŒ 1ê°œ, ì¬ëŒ€íŒŒ 2ëŒ€, ì§„ê°„ì¥ ë°˜ìŠ¤í‘¼, ê³ ì¶§ê°€ë£¨ 1ìŠ¤í‘¼
ì¶œë ¥:
{{
  "title": "ë¼ì§€ê³ ê¸° ê¹€ì¹˜ì°Œê°œ",
  "ingredients": ["ë¼ì§€ê³ ê¸°", "ê¹€ì¹˜", "ë‘ë¶€", "ì–‘íŒŒ", "ëŒ€íŒŒ", "ê°„ì¥", "ê³ ì¶”"],
  "instructions": "1. ë‹¬êµ° ëƒ„ë¹„ì— ë¼ì§€ê³ ê¸°ë¥¼ 200g ë„£ê³  ì¤‘ë¶ˆì—ì„œ ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ì•½ 3ë¶„ê°„ ë³¶ì•„ì¤ë‹ˆë‹¤.\\n2. ë¼ì§€ê³ ê¸°ê°€ ìµìœ¼ë©´ ê¹€ì¹˜ë¥¼ 300g ë„£ê³  5ë¶„ê°„ í•¨ê»˜ ì¶©ë¶„íˆ ë³¶ì•„ ê¹Šì€ ë§›ì„ ë”í•´ì¤ë‹ˆë‹¤.\\n3. ë¬¼ í•œ ì»µì„ ë¶“ê³  ë“ì–´ì˜¤ë¥´ë©´, ê°„ì¥ê³¼ ê³ ì¶§ê°€ë£¨ë¥¼ ê°ê° ë°˜ ìŠ¤í‘¼, í•œ ìŠ¤í‘¼ì”© ë„£ê³  ì¤‘ë¶ˆì—ì„œ 10ë¶„ê°„ ë” ë“ì—¬ì¤ë‹ˆë‹¤.\\n4. ë§ˆì§€ë§‰ìœ¼ë¡œ ë‘ë¶€, ì–‘íŒŒ, ëŒ€íŒŒë¥¼ ì˜ê²Œ ì°ì–´ë„£ê³  5ë¶„ê°„ í•œì†Œë” ë” ë“ì—¬ ì™„ì„±í•©ë‹ˆë‹¤."
}}
```

ì¤‘ìš”: JSON í˜•ì‹ ì™¸ì— ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."""
    user_prompt = f"ë‹¤ìŒ ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì¤˜:\n\n---\n{page_text}\n---"

    response = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.2, max_tokens=1024
    )
    
    try:
        content = json.loads(response.choices[0].message.content)
        if isinstance(content.get("ingredients"), str):
            content["ingredients"] = [item.strip() for item in content["ingredients"].split(',')]
        return content
    except (json.JSONDecodeError, AttributeError) as e:
        logger.error(f"LLM JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return {}

def _extract_recipe_url(query: str) -> Optional[str]:
    """ì¿¼ë¦¬ ë¬¸ìì—´ì—ì„œ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    match = re.search(r'URL:\s*(https?://[^\s]+)', query)
    if match:
        return match.group(1)
    logger.warning(f"ì¿¼ë¦¬ì—ì„œ URLì„ ì°¾ì§€ ëª»í•¨: {query}")
    return None

def _format_recipe_content(structured_content: Dict[str, Any], user_preferences: Dict[str, Any] = None) -> str:
    """êµ¬ì¡°í™”ëœ ë ˆì‹œí”¼ ë°ì´í„°ë¥¼ AIMessageì— í‘œì‹œí•  ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    title = structured_content.get("title", "ë ˆì‹œí”¼ ì •ë³´")
    ingredients = structured_content.get("ingredients", [])
    instructions = structured_content.get("instructions", "ì¡°ë¦¬ë²• ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    ingredients_text = "\n".join(f"- {ing}" for ing in ingredients[:10])
    if len(ingredients) > 10:
        ingredients_text += "\n- ë“±..."

    personalized_note = ""
    if user_preferences:
        if user_preferences.get("vegan"):
            personalized_note += "**ğŸŒ± ë¹„ê±´ ë ˆì‹œí”¼ë¡œ ê°œì¸ë§ì¶¤í™”ë˜ì—ˆìŠµë‹ˆë‹¤.**\n"
        if user_preferences.get("allergy"):
            personalized_note += f"**âš ï¸ ì•ŒëŸ¬ì§€({user_preferences['allergy']}) ì •ë³´ê°€ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.**\n"
        if user_preferences.get("unfavorite"):
            personalized_note += f"**âŒ ì„ í˜¸í•˜ì§€ ì•ŠëŠ” ìŒì‹({user_preferences['unfavorite']})ì´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.**\n"
        if personalized_note:
            personalized_note += "\n"

    formatted_message = (
        f"**{title}**\n\n"
        f"{personalized_note}"
        f"**í•„ìš”í•œ ì¬ë£Œ:**\n{ingredients_text}\n\n"
        f"**ì¡°ë¦¬ë²• ìš”ì•½:**\n{instructions}\n\n"
        "---\n"
        "**ìš°ì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì¶”ì²œ ì¬ë£Œë“¤ì„ ë°”ë¡œ ì¥ë°”êµ¬ë‹ˆì— ë‹´ì•„ë³´ì„¸ìš”!**\n"
        "**í•„ìš”í•œ ì¬ë£Œê°€ ìƒí’ˆì— ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ìƒí’ˆì´ ì¶”ì²œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**"
    )
    
    return formatted_message
